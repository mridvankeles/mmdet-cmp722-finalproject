{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-BgIzdUah-M"
      },
      "source": [
        "# MMDet-AITOD Training and Testing Notebook for Google Colab\n",
        "\n",
        "This notebook trains and tests models using data from Google Drive.\n",
        "\n",
        "## Setup Instructions:\n",
        "1. Upload your files to Google Drive:\n",
        "   - `mmdet-nwdrka` repository\n",
        "   - Config files (or they can be in the repo)\n",
        "   - Dataset (AI-TODv2)\n",
        "2. Update the paths in CELL 1 according to your Drive structure\n",
        "3. Run all cells in order\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVlxhtWqah-P",
        "outputId": "7c6fe521-bf0c-43ef-c690-9b3ce4bad133"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Configuration:\n",
            "  Repository: /content/drive/MyDrive/mmdet_nwdrka/mmdet-nwdrka\n",
            "  COCOAPI: /content/drive/MyDrive/mmdet_nwdrka/cocoapi-aitod-master/aitodpycocotools\n",
            "  Requirements: /content/drive/MyDrive/mmdet_nwdrka/requirements_mmdet.txt\n",
            "  Dataset location: /content/drive/MyDrive/mmdet_nwdrka/mmdet-nwdrka/data/aitod_super\n",
            "  Python 3.8 venv: /content/py38\n",
            "  Config: nwd_rka/aitod_super_faster_r50_iou_1x.py\n",
            "  Output: /content/drive/MyDrive/outputs\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 1: Mount Google Drive and Configure Paths\n",
        "# ============================================================================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Configure your paths here\n",
        "DRIVE_ROOT = '/content/drive/MyDrive'\n",
        "REPO_PATH = f'{DRIVE_ROOT}/mmdet_nwdrka/mmdet-nwdrka'\n",
        "COCOAPI_PATH = f'{DRIVE_ROOT}/mmdet_nwdrka/cocoapi-aitod-master/aitodpycocotools'\n",
        "REQUIREMENTS_PATH = f'{DRIVE_ROOT}/mmdet_nwdrka/requirements_mmdet.txt'\n",
        "DATASET_EXTRACTED_PATH = f'{DRIVE_ROOT}/mmdet_nwdrka/mmdet-nwdrka/data/aitod_super'\n",
        "OUTPUT_PATH = f'{DRIVE_ROOT}/outputs'\n",
        "\n",
        "# Python 3.8 virtual environment path\n",
        "VENV_PATH = '/content/py38'\n",
        "VENV_ACTIVATE = f'source {VENV_PATH}/bin/activate'\n",
        "VENV_PYTHON = f'{VENV_PATH}/bin/python'\n",
        "\n",
        "# Training configuration\n",
        "CONFIG_FILE = 'nwd_rka/aitod_super_faster_r50_iou_1x.py'  # Change this to your config\n",
        "\n",
        "print(\"Configuration:\")\n",
        "print(f\"  Repository: {REPO_PATH}\")\n",
        "print(f\"  COCOAPI: {COCOAPI_PATH}\")\n",
        "print(f\"  Requirements: {REQUIREMENTS_PATH}\")\n",
        "print(f\"  Dataset location: {DATASET_EXTRACTED_PATH}\")\n",
        "print(f\"  Python 3.8 venv: {VENV_PATH}\")\n",
        "print(f\"  Config: {CONFIG_FILE}\")\n",
        "print(f\"  Output: {OUTPUT_PATH}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gctOnnvvah-S",
        "outputId": "c9dd41cf-76d1-48b1-a83f-3b379f50fbe7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> 1) Python 3.8 kuruluyor...\n",
            "Get:1 https://cli.github.com/packages stable InRelease [3,917 B]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:4 https://cli.github.com/packages stable/main amd64 Packages [345 B]\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:7 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,225 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:10 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,860 kB]\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,287 kB]\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,572 kB]\n",
            "Hit:13 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [6,205 kB]\n",
            "Hit:16 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:17 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [69.2 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,633 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,598 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,966 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,411 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [37.2 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [83.9 kB]\n",
            "Fetched 38.3 MB in 3s (13.7 MB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libpython3.8-minimal libpython3.8-stdlib python3.8-lib2to3 python3.8-minimal\n",
            "Suggested packages:\n",
            "  binfmt-support\n",
            "The following NEW packages will be installed:\n",
            "  libpython3.8-minimal libpython3.8-stdlib python3.8 python3.8-distutils\n",
            "  python3.8-lib2to3 python3.8-minimal python3.8-venv\n",
            "0 upgraded, 7 newly installed, 0 to remove and 54 not upgraded.\n",
            "Need to get 8,013 kB of archives.\n",
            "After this operation, 22.9 MB of additional disk space will be used.\n",
            "Get:1 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.8-minimal amd64 3.8.20-1+jammy1 [796 kB]\n",
            "Get:2 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-minimal amd64 3.8.20-1+jammy1 [2,023 kB]\n",
            "Get:3 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.8-stdlib amd64 3.8.20-1+jammy1 [1,817 kB]\n",
            "Get:4 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8 amd64 3.8.20-1+jammy1 [440 kB]\n",
            "Get:5 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-lib2to3 all 3.8.20-1+jammy1 [126 kB]\n",
            "Get:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-distutils all 3.8.20-1+jammy1 [193 kB]\n",
            "Get:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-venv amd64 3.8.20-1+jammy1 [2,618 kB]\n",
            "Fetched 8,013 kB in 16s (496 kB/s)\n",
            "Selecting previously unselected package libpython3.8-minimal:amd64.\n",
            "(Reading database ... 121689 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libpython3.8-minimal_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.8-minimal:amd64 (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8-minimal.\n",
            "Preparing to unpack .../1-python3.8-minimal_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.8-minimal (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package libpython3.8-stdlib:amd64.\n",
            "Preparing to unpack .../2-libpython3.8-stdlib_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.8-stdlib:amd64 (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8.\n",
            "Preparing to unpack .../3-python3.8_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.8 (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8-lib2to3.\n",
            "Preparing to unpack .../4-python3.8-lib2to3_3.8.20-1+jammy1_all.deb ...\n",
            "Unpacking python3.8-lib2to3 (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8-distutils.\n",
            "Preparing to unpack .../5-python3.8-distutils_3.8.20-1+jammy1_all.deb ...\n",
            "Unpacking python3.8-distutils (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8-venv.\n",
            "Preparing to unpack .../6-python3.8-venv_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.8-venv (3.8.20-1+jammy1) ...\n",
            "Setting up libpython3.8-minimal:amd64 (3.8.20-1+jammy1) ...\n",
            "Setting up python3.8-lib2to3 (3.8.20-1+jammy1) ...\n",
            "Setting up python3.8-minimal (3.8.20-1+jammy1) ...\n",
            "Setting up python3.8-distutils (3.8.20-1+jammy1) ...\n",
            "Setting up libpython3.8-stdlib:amd64 (3.8.20-1+jammy1) ...\n",
            "Setting up python3.8 (3.8.20-1+jammy1) ...\n",
            "Setting up python3.8-venv (3.8.20-1+jammy1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "\n",
            ">>> 2) Python 3.8 venv oluşturuluyor: /content/py38\n",
            "\n",
            ">>> 3) Venv'e giriliyor ve pip/setuptools/wheel güncelleniyor...\n",
            "Requirement already satisfied: pip in ./py38/lib/python3.8/site-packages (23.0.1)\n",
            "Collecting pip\n",
            "  Downloading pip-25.0.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in ./py38/lib/python3.8/site-packages (56.0.0)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-75.3.2-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wheel\n",
            "  Downloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wheel, setuptools, pip\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 56.0.0\n",
            "    Uninstalling setuptools-56.0.0:\n",
            "      Successfully uninstalled setuptools-56.0.0\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.0.1\n",
            "    Uninstalling pip-23.0.1:\n",
            "      Successfully uninstalled pip-23.0.1\n",
            "Successfully installed pip-25.0.1 setuptools-75.3.2 wheel-0.45.1\n",
            "\n",
            ">>> 4) PyTorch 1.13.1 + cu117 kuruluyor...\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.13.1+cu117\n",
            "  Downloading https://download.pytorch.org/whl/cu117/torch-1.13.1%2Bcu117-cp38-cp38-linux_x86_64.whl (1801.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 GB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /simple/torchvision/\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting torchvision==0.14.1+cu117\n",
            "  Downloading https://download.pytorch.org/whl/cu117/torchvision-0.14.1%2Bcu117-cp38-cp38-linux_x86_64.whl (24.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.3/24.3 MB\u001b[0m \u001b[31m80.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==0.13.1\n",
            "  Downloading https://download.pytorch.org/whl/rocm5.2/torchaudio-0.13.1%2Brocm5.2-cp38-cp38-linux_x86_64.whl (3.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m128.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions (from torch==1.13.1+cu117)\n",
            "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting numpy (from torchvision==0.14.1+cu117)\n",
            "  Downloading numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting requests (from torchvision==0.14.1+cu117)\n",
            "  Downloading requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision==0.14.1+cu117)\n",
            "  Downloading pillow-10.4.0-cp38-cp38-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting charset_normalizer<4,>=2 (from requests->torchvision==0.14.1+cu117)\n",
            "  Downloading charset_normalizer-3.4.4-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
            "Collecting idna<4,>=2.5 (from requests->torchvision==0.14.1+cu117)\n",
            "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->torchvision==0.14.1+cu117)\n",
            "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests->torchvision==0.14.1+cu117)\n",
            "  Downloading certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
            "Downloading pillow-10.4.0-cp38-cp38-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m95.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m123.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.4-py3-none-any.whl (64 kB)\n",
            "Downloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
            "Downloading certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
            "Downloading charset_normalizer-3.4.4-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (147 kB)\n",
            "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
            "Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
            "Installing collected packages: urllib3, typing-extensions, pillow, numpy, idna, charset_normalizer, certifi, torch, requests, torchvision, torchaudio\n",
            "Successfully installed certifi-2025.11.12 charset_normalizer-3.4.4 idna-3.11 numpy-1.24.4 pillow-10.4.0 requests-2.32.4 torch-1.13.1+cu117 torchaudio-0.13.1+rocm5.2 torchvision-0.14.1+cu117 typing-extensions-4.13.2 urllib3-2.2.3\n",
            "\n",
            ">>> 5) openmim ve mmcv-full==1.7.1 kuruluyor...\n",
            "Collecting openmim\n",
            "  Downloading openmim-0.3.9-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Collecting Click (from openmim)\n",
            "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting colorama (from openmim)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting model-index (from openmim)\n",
            "  Downloading model_index-0.1.11-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting opendatalab (from openmim)\n",
            "  Downloading opendatalab-0.0.10-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting pandas (from openmim)\n",
            "  Downloading pandas-2.0.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: pip>=19.3 in ./py38/lib/python3.8/site-packages (from openmim) (25.0.1)\n",
            "Requirement already satisfied: requests in ./py38/lib/python3.8/site-packages (from openmim) (2.32.4)\n",
            "Collecting rich (from openmim)\n",
            "  Downloading rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting tabulate (from openmim)\n",
            "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
            "Collecting pyyaml (from model-index->openmim)\n",
            "  Downloading PyYAML-6.0.3-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting markdown (from model-index->openmim)\n",
            "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting ordered-set (from model-index->openmim)\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting pycryptodome (from opendatalab->openmim)\n",
            "  Downloading pycryptodome-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting tqdm (from opendatalab->openmim)\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting openxlab (from opendatalab->openmim)\n",
            "  Downloading openxlab-0.1.3-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in ./py38/lib/python3.8/site-packages (from requests->openmim) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./py38/lib/python3.8/site-packages (from requests->openmim) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./py38/lib/python3.8/site-packages (from requests->openmim) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./py38/lib/python3.8/site-packages (from requests->openmim) (2025.11.12)\n",
            "Collecting python-dateutil>=2.8.2 (from pandas->openmim)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2020.1 (from pandas->openmim)\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.1 (from pandas->openmim)\n",
            "  Downloading tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: numpy>=1.20.3 in ./py38/lib/python3.8/site-packages (from pandas->openmim) (1.24.4)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich->openmim)\n",
            "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting pygments<3.0.0,>=2.13.0 (from rich->openmim)\n",
            "  Downloading pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->openmim)\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas->openmim)\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting importlib-metadata>=4.4 (from markdown->model-index->openmim)\n",
            "  Downloading importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting filelock~=3.14.0 (from openxlab->opendatalab->openmim)\n",
            "  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting oss2~=2.17.0 (from openxlab->opendatalab->openmim)\n",
            "  Downloading oss2-2.17.0.tar.gz (259 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting packaging~=24.0 (from openxlab->opendatalab->openmim)\n",
            "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting pytz>=2020.1 (from pandas->openmim)\n",
            "  Downloading pytz-2023.4-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting requests (from openmim)\n",
            "  Downloading requests-2.28.2-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting rich (from openmim)\n",
            "  Downloading rich-13.4.2-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting setuptools~=60.2.0 (from openxlab->opendatalab->openmim)\n",
            "  Downloading setuptools-60.2.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting tqdm (from opendatalab->openmim)\n",
            "  Downloading tqdm-4.65.2-py3-none-any.whl.metadata (56 kB)\n",
            "Collecting urllib3<1.27,>=1.21.1 (from requests->openmim)\n",
            "  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
            "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in ./py38/lib/python3.8/site-packages (from rich->openmim) (4.13.2)\n",
            "Collecting zipp>=3.20 (from importlib-metadata>=4.4->markdown->model-index->openmim)\n",
            "  Downloading zipp-3.20.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting crcmod>=1.7 (from oss2~=2.17.0->openxlab->opendatalab->openmim)\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting aliyun-python-sdk-kms>=2.4.1 (from oss2~=2.17.0->openxlab->opendatalab->openmim)\n",
            "  Downloading aliyun_python_sdk_kms-2.16.5-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting aliyun-python-sdk-core>=2.13.12 (from oss2~=2.17.0->openxlab->opendatalab->openmim)\n",
            "  Downloading aliyun-python-sdk-core-2.16.0.tar.gz (449 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jmespath<1.0.0,>=0.9.3 (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim)\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting cryptography>=3.0.0 (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim)\n",
            "  Downloading cryptography-46.0.3-cp38-abi3-manylinux_2_34_x86_64.whl.metadata (5.7 kB)\n",
            "Collecting cffi>=1.14 (from cryptography>=3.0.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim)\n",
            "  Downloading cffi-1.17.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting pycparser (from cffi>=1.14->cryptography>=3.0.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim)\n",
            "  Downloading pycparser-2.23-py3-none-any.whl.metadata (993 bytes)\n",
            "Downloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\n",
            "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading model_index-0.1.11-py3-none-any.whl (34 kB)\n",
            "Downloading opendatalab-0.0.10-py3-none-any.whl (29 kB)\n",
            "Downloading pandas-2.0.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m172.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
            "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "Downloading pygments-2.19.2-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Downloading tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
            "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
            "Downloading openxlab-0.1.3-py3-none-any.whl (314 kB)\n",
            "Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
            "Downloading rich-13.4.2-py3-none-any.whl (239 kB)\n",
            "Downloading pytz-2023.4-py2.py3-none-any.whl (506 kB)\n",
            "Downloading PyYAML-6.0.3-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (806 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.0/806.0 kB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.65.2-py3-none-any.whl (77 kB)\n",
            "Downloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
            "Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Downloading pycryptodome-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m140.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filelock-3.14.0-py3-none-any.whl (12 kB)\n",
            "Downloading importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\n",
            "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Downloading packaging-24.2-py3-none-any.whl (65 kB)\n",
            "Downloading setuptools-60.2.0-py3-none-any.whl (953 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.1/953.1 kB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading aliyun_python_sdk_kms-2.16.5-py2.py3-none-any.whl (99 kB)\n",
            "Downloading zipp-3.20.2-py3-none-any.whl (9.2 kB)\n",
            "Downloading cryptography-46.0.3-cp38-abi3-manylinux_2_34_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m178.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Downloading cffi-1.17.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (446 kB)\n",
            "Downloading pycparser-2.23-py3-none-any.whl (118 kB)\n",
            "Building wheels for collected packages: oss2, aliyun-python-sdk-core, crcmod\n",
            "  Building wheel for oss2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for oss2: filename=oss2-2.17.0-py3-none-any.whl size=112370 sha256=447935ff49afdc5f485ea4257fa3184db4cb5bae04fdaa7a1b0bef10764d3359\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/f1/a7/a20c3f53c7dbd8a1e5aa17ab1759465203b4ee46d6b3994dd2\n",
            "  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for aliyun-python-sdk-core: filename=aliyun_python_sdk_core-2.16.0-py3-none-any.whl size=535315 sha256=18d9e6f16870aa1551001b96a597309a6c319d785c44edc0687e100f8c735b5b\n",
            "  Stored in directory: /root/.cache/pip/wheels/b2/49/69/4ff7cddf922bb14b3cd172290d83582ec72051d43333e70b69\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-py3-none-any.whl size=18834 sha256=53ab0b33496c8dc34b0a11bae1c62bac4c4b95353c5eaddaf53d52b9ca869da6\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/5a/02/f3acf982a026f3319fb3e798a8dca2d48fafee7761788562e9\n",
            "Successfully built oss2 aliyun-python-sdk-core crcmod\n",
            "Installing collected packages: pytz, crcmod, zipp, urllib3, tzdata, tqdm, tabulate, six, setuptools, pyyaml, pygments, pycryptodome, pycparser, packaging, ordered-set, mdurl, jmespath, filelock, colorama, Click, requests, python-dateutil, markdown-it-py, importlib-metadata, cffi, rich, pandas, markdown, cryptography, model-index, aliyun-python-sdk-core, aliyun-python-sdk-kms, oss2, openxlab, opendatalab, openmim\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.2.3\n",
            "    Uninstalling urllib3-2.2.3:\n",
            "      Successfully uninstalled urllib3-2.2.3\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.3.2\n",
            "    Uninstalling setuptools-75.3.2:\n",
            "      Successfully uninstalled setuptools-75.3.2\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "Successfully installed Click-8.1.8 aliyun-python-sdk-core-2.16.0 aliyun-python-sdk-kms-2.16.5 cffi-1.17.1 colorama-0.4.6 crcmod-1.7 cryptography-46.0.3 filelock-3.14.0 importlib-metadata-8.5.0 jmespath-0.10.0 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 model-index-0.1.11 opendatalab-0.0.10 openmim-0.3.9 openxlab-0.1.3 ordered-set-4.1.0 oss2-2.17.0 packaging-24.2 pandas-2.0.3 pycparser-2.23 pycryptodome-3.23.0 pygments-2.19.2 python-dateutil-2.9.0.post0 pytz-2023.4 pyyaml-6.0.3 requests-2.28.2 rich-13.4.2 setuptools-60.2.0 six-1.17.0 tabulate-0.9.0 tqdm-4.65.2 tzdata-2025.3 urllib3-1.26.20 zipp-3.20.2\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu117/torch1.13.0/index.html\n",
            "Collecting mmcv-full==1.7.1\n",
            "  Downloading https://download.openmmlab.com/mmcv/dist/cu117/torch1.13.0/mmcv_full-1.7.1-cp38-cp38-manylinux1_x86_64.whl (46.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting addict (from mmcv-full==1.7.1)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: numpy in ./py38/lib/python3.8/site-packages (from mmcv-full==1.7.1) (1.24.4)\n",
            "Requirement already satisfied: packaging in ./py38/lib/python3.8/site-packages (from mmcv-full==1.7.1) (24.2)\n",
            "Requirement already satisfied: Pillow in ./py38/lib/python3.8/site-packages (from mmcv-full==1.7.1) (10.4.0)\n",
            "Requirement already satisfied: pyyaml in ./py38/lib/python3.8/site-packages (from mmcv-full==1.7.1) (6.0.3)\n",
            "Collecting yapf (from mmcv-full==1.7.1)\n",
            "  Downloading yapf-0.43.0-py3-none-any.whl.metadata (46 kB)\n",
            "Collecting opencv-python>=3 (from mmcv-full==1.7.1)\n",
            "  Downloading opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
            "Collecting platformdirs>=3.5.1 (from yapf->mmcv-full==1.7.1)\n",
            "  Downloading platformdirs-4.3.6-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting tomli>=2.0.1 (from yapf->mmcv-full==1.7.1)\n",
            "  Downloading tomli-2.3.0-py3-none-any.whl.metadata (10 kB)\n",
            "Downloading opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (67.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m184.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading yapf-0.43.0-py3-none-any.whl (256 kB)\n",
            "Downloading platformdirs-4.3.6-py3-none-any.whl (18 kB)\n",
            "Downloading tomli-2.3.0-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: addict, tomli, platformdirs, opencv-python, yapf, mmcv-full\n",
            "Successfully installed addict-2.4.0 mmcv-full-1.7.1 opencv-python-4.12.0.88 platformdirs-4.3.6 tomli-2.3.0 yapf-0.43.0\n",
            "\n",
            ">>> 6) mmdet kuruluyor...\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu117/torch1.13.0/index.html\n",
            "Collecting mmdet\n",
            "  Downloading mmdet-3.3.0-py3-none-any.whl.metadata (29 kB)\n",
            "Ignoring mmcv: markers 'extra == \"mim\"' don't match your environment\n",
            "Ignoring mmengine: markers 'extra == \"mim\"' don't match your environment\n",
            "Collecting matplotlib (from mmdet)\n",
            "  Downloading matplotlib-3.7.5-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: numpy in ./py38/lib/python3.8/site-packages (from mmdet) (1.24.4)\n",
            "Collecting pycocotools (from mmdet)\n",
            "  Downloading pycocotools-2.0.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting scipy (from mmdet)\n",
            "  Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "Collecting shapely (from mmdet)\n",
            "  Downloading shapely-2.0.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: six in ./py38/lib/python3.8/site-packages (from mmdet) (1.17.0)\n",
            "Collecting terminaltables (from mmdet)\n",
            "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: tqdm in ./py38/lib/python3.8/site-packages (from mmdet) (4.65.2)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib->mmdet)\n",
            "  Downloading contourpy-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.9 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib->mmdet)\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib->mmdet)\n",
            "  Downloading fonttools-4.57.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (102 kB)\n",
            "Collecting kiwisolver>=1.0.1 (from matplotlib->mmdet)\n",
            "  Downloading kiwisolver-1.4.7-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in ./py38/lib/python3.8/site-packages (from matplotlib->mmdet) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in ./py38/lib/python3.8/site-packages (from matplotlib->mmdet) (10.4.0)\n",
            "Collecting pyparsing>=2.3.1 (from matplotlib->mmdet)\n",
            "  Downloading pyparsing-3.1.4-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in ./py38/lib/python3.8/site-packages (from matplotlib->mmdet) (2.9.0.post0)\n",
            "Collecting importlib-resources>=3.2.0 (from matplotlib->mmdet)\n",
            "  Downloading importlib_resources-6.4.5-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: zipp>=3.1.0 in ./py38/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib->mmdet) (3.20.2)\n",
            "Downloading mmdet-3.3.0-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.7.5-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.2/9.2 MB\u001b[0m \u001b[31m159.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycocotools-2.0.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (439 kB)\n",
            "Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m177.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shapely-2.0.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m105.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
            "Downloading contourpy-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
            "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading fonttools-4.57.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m177.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
            "Downloading kiwisolver-1.4.7-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyparsing-3.1.4-py3-none-any.whl (104 kB)\n",
            "Installing collected packages: terminaltables, shapely, scipy, pyparsing, kiwisolver, importlib-resources, fonttools, cycler, contourpy, matplotlib, pycocotools, mmdet\n",
            "Successfully installed contourpy-1.1.1 cycler-0.12.1 fonttools-4.57.0 importlib-resources-6.4.5 kiwisolver-1.4.7 matplotlib-3.7.5 mmdet-3.3.0 pycocotools-2.0.7 pyparsing-3.1.4 scipy-1.10.1 shapely-2.0.7 terminaltables-3.1.10\n",
            "\n",
            ">>> 7) Found requirements.txt at: /content/drive/MyDrive/mmdet_nwdrka/requirements_mmdet.txt\n",
            "Installing other dependencies from requirements.txt (excluding mmcv/mmdet)...\n",
            "Processing /croot/mkl_fft_1695058164594/work (from -r /content/requirements_filtered.txt (line 56))\n",
            "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/croot/mkl_fft_1695058164594/work'\n",
            "\u001b[0m\u001b[31m\n",
            "\u001b[0m✓ Other dependencies installed from requirements.txt\n",
            "\n",
            ">>> 8) Installation verification...\n",
            "/bin/bash: line 1: {VENV_ACTIVATE}: command not found\n",
            "\n",
            ">>> 9) Configuring notebook to use Python 3.8 venv...\n",
            "✓ Added /content/py38/lib/python3.8/site-packages to sys.path\n",
            "✓ Python 3.8 venv available: Python 3.8.20\n",
            "\n",
            ">>> BİTTİ.\n",
            "\n",
            "Bu ortamı kullanmak için: source /content/py38/bin/activate\n",
            "Notebook Python path configured to use venv packages.\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 2: Setup Python 3.8 Environment and Install Dependencies\n",
        "# ============================================================================\n",
        "import os\n",
        "import shutil\n",
        "import sys\n",
        "\n",
        "print(\">>> 1) Python 3.8 kuruluyor...\")\n",
        "!apt-get update -y\n",
        "!apt-get install -y python3.8 python3.8-venv python3.8-distutils\n",
        "\n",
        "print(f\"\\n>>> 2) Python 3.8 venv oluşturuluyor: {VENV_PATH}\")\n",
        "!python3.8 -m venv {VENV_PATH}\n",
        "\n",
        "print(f\"\\n>>> 3) Venv'e giriliyor ve pip/setuptools/wheel güncelleniyor...\")\n",
        "!{VENV_ACTIVATE} && python -m pip install --upgrade pip setuptools wheel\n",
        "\n",
        "print(\"\\n>>> 4) PyTorch 1.13.1 + cu117 kuruluyor...\")\n",
        "!{VENV_ACTIVATE} && python -m pip install \\\n",
        "  torch==1.13.1+cu117 \\\n",
        "  torchvision==0.14.1+cu117 \\\n",
        "  torchaudio==0.13.1 \\\n",
        "  -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "print(\"\\n>>> 5) openmim ve mmcv-full==1.7.1 kuruluyor...\")\n",
        "!{VENV_ACTIVATE} && python -m pip install -U openmim\n",
        "!{VENV_ACTIVATE} && mim install \"mmcv-full==1.7.1\"\n",
        "\n",
        "print(\"\\n>>> 6) mmdet kuruluyor...\")\n",
        "!{VENV_ACTIVATE} && mim install mmdet\n",
        "\n",
        "# Install other dependencies from requirements.txt in Drive\n",
        "if os.path.exists(REQUIREMENTS_PATH):\n",
        "    print(f\"\\n>>> 7) Found requirements.txt at: {REQUIREMENTS_PATH}\")\n",
        "    # Copy to local directory for installation\n",
        "    LOCAL_REQUIREMENTS = '/content/requirements.txt'\n",
        "    shutil.copy(REQUIREMENTS_PATH, LOCAL_REQUIREMENTS)\n",
        "\n",
        "    # Read requirements and filter out mmcv and mmdet (already installed via mim)\n",
        "    with open(LOCAL_REQUIREMENTS, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    # Filter out mmcv and mmdet related packages\n",
        "    filtered_lines = []\n",
        "    for line in lines:\n",
        "        line_stripped = line.strip().lower()\n",
        "        if line_stripped and not line_stripped.startswith('#'):\n",
        "            # Skip mmcv and mmdet packages\n",
        "            if 'mmcv' not in line_stripped and 'mmdet' not in line_stripped:\n",
        "                filtered_lines.append(line)\n",
        "\n",
        "    # Write filtered requirements\n",
        "    if filtered_lines:\n",
        "        FILTERED_REQUIREMENTS = '/content/requirements_filtered.txt'\n",
        "        with open(FILTERED_REQUIREMENTS, 'w') as f:\n",
        "            f.writelines(filtered_lines)\n",
        "        print(\"Installing other dependencies from requirements.txt (excluding mmcv/mmdet)...\")\n",
        "        !{VENV_ACTIVATE} && pip install -r {FILTERED_REQUIREMENTS}\n",
        "        print(\"✓ Other dependencies installed from requirements.txt\")\n",
        "    else:\n",
        "        print(\"All dependencies in requirements.txt are mmcv/mmdet (already installed)\")\n",
        "else:\n",
        "    print(f\"\\n>>> 7) Note: requirements.txt not found at {REQUIREMENTS_PATH}\")\n",
        "    print(\"Installing common dependencies...\")\n",
        "    !{VENV_ACTIVATE} && pip install matplotlib numpy pycocotools six terminaltables opencv-python pillow\n",
        "\n",
        "# Verify installation\n",
        "print(\"\\n>>> 8) Installation verification...\")\n",
        "!{VENV_ACTIVATE} && python -c \"import sys, torch, mmcv; print(f'Python: {sys.version}'); print(f'PyTorch: {torch.__version__}'); print(f'CUDA available: {torch.cuda.is_available()}'); print(f'MMCV: {mmcv.__version__}')\"\n",
        "\n",
        "# Configure notebook to use Python 3.8 venv for inline Python code\n",
        "print(\"\\n>>> 9) Configuring notebook to use Python 3.8 venv...\")\n",
        "venv_python = f'{VENV_PATH}/bin/python'\n",
        "venv_site_packages = f'{VENV_PATH}/lib/python3.8/site-packages'\n",
        "\n",
        "# Add venv site-packages to Python path\n",
        "if venv_site_packages not in sys.path:\n",
        "    sys.path.insert(0, venv_site_packages)\n",
        "    print(f\"✓ Added {venv_site_packages} to sys.path\")\n",
        "\n",
        "# Verify we can import from venv\n",
        "try:\n",
        "    import subprocess\n",
        "    result = subprocess.run([venv_python, '--version'], capture_output=True, text=True)\n",
        "    print(f\"✓ Python 3.8 venv available: {result.stdout.strip()}\")\n",
        "except:\n",
        "    print(\"Note: Could not verify venv Python version\")\n",
        "\n",
        "print(\"\\n>>> BİTTİ.\")\n",
        "print(f\"\\nBu ortamı kullanmak için: {VENV_ACTIVATE}\")\n",
        "print(\"Notebook Python path configured to use venv packages.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "teKs3NIUeJko"
      },
      "outputs": [],
      "source": [
        "# pip install torch1.13.0 cuda\n",
        "\n",
        "#!pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu117\n",
        "#!pip install -U pip setuptools wheel\n",
        "#!pip install -f https://download.openmmlab.com/mmcv/dist/cu117/torch1.13/index.html \"mmcv==1.7.1\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewpQZAZwz0NQ",
        "outputId": "4e038d21-cc1c-4964-e02f-0830d24a13e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Python 3.8 ortamı aktive ediliyor...\n",
            ">> Python 3.8 geliştirme dosyaları yükleniyor...\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "The following additional packages will be installed:\n",
            "  libpython3.8 libpython3.8-dev\n",
            "The following NEW packages will be installed:\n",
            "  libpython3.8 libpython3.8-dev python3.8-dev\n",
            "0 upgraded, 3 newly installed, 0 to remove and 54 not upgraded.\n",
            "Need to get 6,687 kB of archives.\n",
            "After this operation, 25.0 MB of additional disk space will be used.\n",
            "Get:1 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.8 amd64 3.8.20-1+jammy1 [1,798 kB]\n",
            "Get:2 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.8-dev amd64 3.8.20-1+jammy1 [4,389 kB]\n",
            "Get:3 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-dev amd64 3.8.20-1+jammy1 [500 kB]\n",
            "Fetched 6,687 kB in 14s (487 kB/s)\n",
            "Selecting previously unselected package libpython3.8:amd64.\r\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 122463 files and directories currently installed.)\r\n",
            "Preparing to unpack .../libpython3.8_3.8.20-1+jammy1_amd64.deb ...\r\n",
            "Unpacking libpython3.8:amd64 (3.8.20-1+jammy1) ...\r\n",
            "Selecting previously unselected package libpython3.8-dev:amd64.\r\n",
            "Preparing to unpack .../libpython3.8-dev_3.8.20-1+jammy1_amd64.deb ...\r\n",
            "Unpacking libpython3.8-dev:amd64 (3.8.20-1+jammy1) ...\r\n",
            "Selecting previously unselected package python3.8-dev.\r\n",
            "Preparing to unpack .../python3.8-dev_3.8.20-1+jammy1_amd64.deb ...\r\n",
            "Unpacking python3.8-dev (3.8.20-1+jammy1) ...\r\n",
            "Setting up libpython3.8:amd64 (3.8.20-1+jammy1) ...\r\n",
            "Setting up libpython3.8-dev:amd64 (3.8.20-1+jammy1) ...\r\n",
            "Setting up python3.8-dev (3.8.20-1+jammy1) ...\r\n",
            "Processing triggers for man-db (2.10.2-1) ...\r\n",
            ">> Mevcut aitodpycocotools uninstall ediliyor...\n",
            ">> pip, cython, numpy, yapf ayarlanıyor...\n",
            "Requirement already satisfied: pip in ./py38/lib/python3.8/site-packages (25.0.1)\n",
            "Requirement already satisfied: setuptools in ./py38/lib/python3.8/site-packages (60.2.0)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-75.3.2-py3-none-any.whl.metadata (6.9 kB)\n",
            "Downloading setuptools-75.3.2-py3-none-any.whl (1.3 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 35.1 MB/s eta 0:00:00\n",
            "Installing collected packages: setuptools\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 60.2.0\n",
            "    Uninstalling setuptools-60.2.0:\n",
            "      Successfully uninstalled setuptools-60.2.0\n",
            "Successfully installed setuptools-75.3.2\n",
            "Collecting cython<3.0.0\n",
            "  Downloading Cython-0.29.37-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata (3.1 kB)\n",
            "Collecting numpy<1.24\n",
            "  Downloading numpy-1.23.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Collecting yapf==0.30.0\n",
            "  Downloading yapf-0.30.0-py2.py3-none-any.whl.metadata (31 kB)\n",
            "Downloading yapf-0.30.0-py2.py3-none-any.whl (190 kB)\n",
            "Downloading Cython-0.29.37-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.9/1.9 MB 60.3 MB/s eta 0:00:00\n",
            "Downloading numpy-1.23.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 17.1/17.1 MB 136.6 MB/s eta 0:00:00\n",
            "Installing collected packages: yapf, numpy, cython\n",
            "  Attempting uninstall: yapf\n",
            "    Found existing installation: yapf 0.43.0\n",
            "    Uninstalling yapf-0.43.0:\n",
            "      Successfully uninstalled yapf-0.43.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.24.4\n",
            "    Uninstalling numpy-1.24.4:\n",
            "      Successfully uninstalled numpy-1.24.4\n",
            "Successfully installed cython-0.29.37 numpy-1.23.5 yapf-0.30.0\n",
            ">> aitodpycocotools GitHub'dan (NO local path!) kuruluyor...\n",
            "Using pip 25.0.1 from /content/py38/lib/python3.8/site-packages/pip (python 3.8)\n",
            "Collecting git+https://github.com/jwwangchn/cocoapi-aitod.git#subdirectory=aitodpycocotools\n",
            "  Cloning https://github.com/jwwangchn/cocoapi-aitod.git to /tmp/pip-req-build-ewwaaqdq\n",
            "  Resolved https://github.com/jwwangchn/cocoapi-aitod.git to commit 44a230ae5197cb89bf9e5e62f313cac3ad30c7af\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: setuptools>=18.0 in ./py38/lib/python3.8/site-packages (from aitodpycocotools==12.0.3) (75.3.2)\n",
            "Requirement already satisfied: cython>=0.27.3 in ./py38/lib/python3.8/site-packages (from aitodpycocotools==12.0.3) (0.29.37)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in ./py38/lib/python3.8/site-packages (from aitodpycocotools==12.0.3) (3.7.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in ./py38/lib/python3.8/site-packages (from matplotlib>=2.1.0->aitodpycocotools==12.0.3) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in ./py38/lib/python3.8/site-packages (from matplotlib>=2.1.0->aitodpycocotools==12.0.3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in ./py38/lib/python3.8/site-packages (from matplotlib>=2.1.0->aitodpycocotools==12.0.3) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in ./py38/lib/python3.8/site-packages (from matplotlib>=2.1.0->aitodpycocotools==12.0.3) (1.4.7)\n",
            "Requirement already satisfied: numpy<2,>=1.20 in ./py38/lib/python3.8/site-packages (from matplotlib>=2.1.0->aitodpycocotools==12.0.3) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in ./py38/lib/python3.8/site-packages (from matplotlib>=2.1.0->aitodpycocotools==12.0.3) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in ./py38/lib/python3.8/site-packages (from matplotlib>=2.1.0->aitodpycocotools==12.0.3) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in ./py38/lib/python3.8/site-packages (from matplotlib>=2.1.0->aitodpycocotools==12.0.3) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in ./py38/lib/python3.8/site-packages (from matplotlib>=2.1.0->aitodpycocotools==12.0.3) (2.9.0.post0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in ./py38/lib/python3.8/site-packages (from matplotlib>=2.1.0->aitodpycocotools==12.0.3) (6.4.5)\n",
            "Requirement already satisfied: zipp>=3.1.0 in ./py38/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib>=2.1.0->aitodpycocotools==12.0.3) (3.20.2)\n",
            "Requirement already satisfied: six>=1.5 in ./py38/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->aitodpycocotools==12.0.3) (1.17.0)\n",
            "Building wheels for collected packages: aitodpycocotools\n",
            "  Building wheel for aitodpycocotools (setup.py): started\n",
            "  Building wheel for aitodpycocotools (setup.py): finished with status 'done'\n",
            "  Created wheel for aitodpycocotools: filename=aitodpycocotools-12.0.3-cp38-cp38-linux_x86_64.whl size=368484 sha256=88e9983ca56ff6cf5deda00ff31690510f12b6c156cd80ed10c4dc522419f592\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-bebwryr8/wheels/10/f2/64/81a8fe48870b73bf4730e308d328e4f787d402dcd565fad16e\n",
            "Successfully built aitodpycocotools\n",
            "Installing collected packages: aitodpycocotools\n",
            "Successfully installed aitodpycocotools-12.0.3\n",
            ">> Kurulum testi:\n",
            "Python: 3.8.20 (default, Sep  7 2024, 18:35:08) \n",
            "[GCC 11.4.0]\n",
            "aitodpycocotools OK: /content/py38/lib/python3.8/site-packages/aitodpycocotools/__init__.py\n",
            "yapf version: 0.30.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Skipping aitodpycocotools as it is not installed.\n",
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "openxlab 0.1.3 requires setuptools~=60.2.0, but you have setuptools 75.3.2 which is incompatible.\n",
            "  Running command git version\n",
            "  git version 2.34.1\n",
            "  Running command git clone --filter=blob:none https://github.com/jwwangchn/cocoapi-aitod.git /tmp/pip-req-build-ewwaaqdq\n",
            "  Cloning into '/tmp/pip-req-build-ewwaaqdq'...\n",
            "  Running command git rev-parse HEAD\n",
            "  44a230ae5197cb89bf9e5e62f313cac3ad30c7af\n",
            "  Running command git rev-parse HEAD\n",
            "  44a230ae5197cb89bf9e5e62f313cac3ad30c7af\n",
            "  Running command python setup.py egg_info\n",
            "  running egg_info\n",
            "  creating /tmp/pip-pip-egg-info-d105o67j/aitodpycocotools.egg-info\n",
            "  writing /tmp/pip-pip-egg-info-d105o67j/aitodpycocotools.egg-info/PKG-INFO\n",
            "  writing dependency_links to /tmp/pip-pip-egg-info-d105o67j/aitodpycocotools.egg-info/dependency_links.txt\n",
            "  writing requirements to /tmp/pip-pip-egg-info-d105o67j/aitodpycocotools.egg-info/requires.txt\n",
            "  writing top-level names to /tmp/pip-pip-egg-info-d105o67j/aitodpycocotools.egg-info/top_level.txt\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-d105o67j/aitodpycocotools.egg-info/SOURCES.txt'\n",
            "  reading manifest file '/tmp/pip-pip-egg-info-d105o67j/aitodpycocotools.egg-info/SOURCES.txt'\n",
            "  reading manifest template 'MANIFEST.in'\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-d105o67j/aitodpycocotools.egg-info/SOURCES.txt'\n",
            "  Running command python setup.py bdist_wheel\n",
            "  running bdist_wheel\n",
            "  running build\n",
            "  running build_py\n",
            "  creating build/lib.linux-x86_64-cpython-38/aitodpycocotools\n",
            "  copying aitodpycocotools/cocoeval.py -> build/lib.linux-x86_64-cpython-38/aitodpycocotools\n",
            "  copying aitodpycocotools/coco.py -> build/lib.linux-x86_64-cpython-38/aitodpycocotools\n",
            "  copying aitodpycocotools/__init__.py -> build/lib.linux-x86_64-cpython-38/aitodpycocotools\n",
            "  copying aitodpycocotools/mask.py -> build/lib.linux-x86_64-cpython-38/aitodpycocotools\n",
            "  running build_ext\n",
            "  cythoning aitodpycocotools/_mask.pyx to aitodpycocotools/_mask.c\n",
            "  /content/py38/lib/python3.8/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /tmp/pip-req-build-ewwaaqdq/aitodpycocotools/aitodpycocotools/_mask.pyx\n",
            "    tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "  building 'aitodpycocotools._mask' extension\n",
            "  creating build/temp.linux-x86_64-cpython-38/aitodpycocotools\n",
            "  creating build/temp.linux-x86_64-cpython-38/common\n",
            "  x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/content/py38/lib/python3.8/site-packages/numpy/core/include -Icommon -I/content/py38/include -I/usr/include/python3.8 -c aitodpycocotools/_mask.c -o build/temp.linux-x86_64-cpython-38/aitodpycocotools/_mask.o\n",
            "  In file included from /content/py38/lib/python3.8/site-packages/numpy/core/include/numpy/ndarraytypes.h:1948,\n",
            "                   from /content/py38/lib/python3.8/site-packages/numpy/core/include/numpy/ndarrayobject.h:12,\n",
            "                   from /content/py38/lib/python3.8/site-packages/numpy/core/include/numpy/arrayobject.h:5,\n",
            "                   from aitodpycocotools/_mask.c:752:\n",
            "  /content/py38/lib/python3.8/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2: warning: #warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [-Wcpp]\n",
            "     17 | #warning \"Using deprecated NumPy API, disable it with \" \\\n",
            "        |  ^~~~~~~\n",
            "  x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/content/py38/lib/python3.8/site-packages/numpy/core/include -Icommon -I/content/py38/include -I/usr/include/python3.8 -c common/maskApi.c -o build/temp.linux-x86_64-cpython-38/common/maskApi.o\n",
            "  common/maskApi.c: In function ‘rleDecode’:\n",
            "  common/maskApi.c:46:7: warning: this ‘for’ clause does not guard... [-Wmisleading-indentation]\n",
            "     46 |       for( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; v=!v; }}\n",
            "        |       ^~~\n",
            "  common/maskApi.c:46:49: note: ...this statement, but the latter is misleadingly indented as if it were guarded by the ‘for’\n",
            "     46 |       for( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; v=!v; }}\n",
            "        |                                                 ^\n",
            "  common/maskApi.c: In function ‘rleFrPoly’:\n",
            "  common/maskApi.c:166:3: warning: this ‘for’ clause does not guard... [-Wmisleading-indentation]\n",
            "    166 |   for(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];\n",
            "        |   ^~~\n",
            "  common/maskApi.c:166:54: note: ...this statement, but the latter is misleadingly indented as if it were guarded by the ‘for’\n",
            "    166 |   for(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];\n",
            "        |                                                      ^\n",
            "  common/maskApi.c:167:3: warning: this ‘for’ clause does not guard... [-Wmisleading-indentation]\n",
            "    167 |   for(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];\n",
            "        |   ^~~\n",
            "  common/maskApi.c:167:54: note: ...this statement, but the latter is misleadingly indented as if it were guarded by the ‘for’\n",
            "    167 |   for(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];\n",
            "        |                                                      ^\n",
            "  common/maskApi.c: In function ‘rleToString’:\n",
            "  common/maskApi.c:212:7: warning: this ‘if’ clause does not guard... [-Wmisleading-indentation]\n",
            "    212 |       if(more) c |= 0x20; c+=48; s[p++]=c;\n",
            "        |       ^~\n",
            "  common/maskApi.c:212:27: note: ...this statement, but the latter is misleadingly indented as if it were guarded by the ‘if’\n",
            "    212 |       if(more) c |= 0x20; c+=48; s[p++]=c;\n",
            "        |                           ^\n",
            "  common/maskApi.c: In function ‘rleFrString’:\n",
            "  common/maskApi.c:220:3: warning: this ‘while’ clause does not guard... [-Wmisleading-indentation]\n",
            "    220 |   while( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;\n",
            "        |   ^~~~~\n",
            "  common/maskApi.c:220:22: note: ...this statement, but the latter is misleadingly indented as if it were guarded by the ‘while’\n",
            "    220 |   while( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;\n",
            "        |                      ^~~~\n",
            "  common/maskApi.c:228:5: warning: this ‘if’ clause does not guard... [-Wmisleading-indentation]\n",
            "    228 |     if(m>2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;\n",
            "        |     ^~\n",
            "  common/maskApi.c:228:34: note: ...this statement, but the latter is misleadingly indented as if it were guarded by the ‘if’\n",
            "    228 |     if(m>2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;\n",
            "        |                                  ^~~~\n",
            "  x86_64-linux-gnu-gcc -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-38/aitodpycocotools/_mask.o build/temp.linux-x86_64-cpython-38/common/maskApi.o -L/usr/lib/x86_64-linux-gnu -o build/lib.linux-x86_64-cpython-38/aitodpycocotools/_mask.cpython-38-x86_64-linux-gnu.so\n",
            "  /content/py38/lib/python3.8/site-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "  !!\n",
            "\n",
            "          ********************************************************************************\n",
            "          Please avoid running ``setup.py`` directly.\n",
            "          Instead, use pypa/build, pypa/installer or other\n",
            "          standards-based tools.\n",
            "\n",
            "          See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "          ********************************************************************************\n",
            "\n",
            "  !!\n",
            "    self.initialize_options()\n",
            "  installing to build/bdist.linux-x86_64/wheel\n",
            "  running install\n",
            "  running install_lib\n",
            "  creating build/bdist.linux-x86_64/wheel\n",
            "  creating build/bdist.linux-x86_64/wheel/aitodpycocotools\n",
            "  copying build/lib.linux-x86_64-cpython-38/aitodpycocotools/cocoeval.py -> build/bdist.linux-x86_64/wheel/./aitodpycocotools\n",
            "  copying build/lib.linux-x86_64-cpython-38/aitodpycocotools/coco.py -> build/bdist.linux-x86_64/wheel/./aitodpycocotools\n",
            "  copying build/lib.linux-x86_64-cpython-38/aitodpycocotools/__init__.py -> build/bdist.linux-x86_64/wheel/./aitodpycocotools\n",
            "  copying build/lib.linux-x86_64-cpython-38/aitodpycocotools/_mask.cpython-38-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/./aitodpycocotools\n",
            "  copying build/lib.linux-x86_64-cpython-38/aitodpycocotools/mask.py -> build/bdist.linux-x86_64/wheel/./aitodpycocotools\n",
            "  running install_egg_info\n",
            "  running egg_info\n",
            "  creating aitodpycocotools.egg-info\n",
            "  writing aitodpycocotools.egg-info/PKG-INFO\n",
            "  writing dependency_links to aitodpycocotools.egg-info/dependency_links.txt\n",
            "  writing requirements to aitodpycocotools.egg-info/requires.txt\n",
            "  writing top-level names to aitodpycocotools.egg-info/top_level.txt\n",
            "  writing manifest file 'aitodpycocotools.egg-info/SOURCES.txt'\n",
            "  reading manifest file 'aitodpycocotools.egg-info/SOURCES.txt'\n",
            "  reading manifest template 'MANIFEST.in'\n",
            "  writing manifest file 'aitodpycocotools.egg-info/SOURCES.txt'\n",
            "  Copying aitodpycocotools.egg-info to build/bdist.linux-x86_64/wheel/./aitodpycocotools-12.0.3-py3.8.egg-info\n",
            "  running install_scripts\n",
            "  creating build/bdist.linux-x86_64/wheel/aitodpycocotools-12.0.3.dist-info/WHEEL\n",
            "  creating '/tmp/pip-wheel-zuypu8ac/aitodpycocotools-12.0.3-cp38-cp38-linux_x86_64.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
            "  adding 'aitodpycocotools/__init__.py'\n",
            "  adding 'aitodpycocotools/_mask.cpython-38-x86_64-linux-gnu.so'\n",
            "  adding 'aitodpycocotools/coco.py'\n",
            "  adding 'aitodpycocotools/cocoeval.py'\n",
            "  adding 'aitodpycocotools/mask.py'\n",
            "  adding 'aitodpycocotools-12.0.3.dist-info/METADATA'\n",
            "  adding 'aitodpycocotools-12.0.3.dist-info/WHEEL'\n",
            "  adding 'aitodpycocotools-12.0.3.dist-info/top_level.txt'\n",
            "  adding 'aitodpycocotools-12.0.3.dist-info/RECORD'\n",
            "  removing build/bdist.linux-x86_64/wheel\n",
            "<stdin>:1: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "set -e\n",
        "echo \">> Python 3.8 ortamı aktive ediliyor...\"\n",
        "source /content/py38/bin/activate\n",
        "\n",
        "echo \">> Python 3.8 geliştirme dosyaları yükleniyor...\"\n",
        "apt-get install -y python3.8-dev\n",
        "\n",
        "echo \">> Mevcut aitodpycocotools uninstall ediliyor...\"\n",
        "python -m pip uninstall -y aitodpycocotools || true\n",
        "\n",
        "echo \">> pip, cython, numpy, yapf ayarlanıyor...\"\n",
        "python -m pip install --upgrade pip setuptools\n",
        "python -m pip install \"cython<3.0.0\" \"numpy<1.24\" \"yapf==0.30.0\"\n",
        "\n",
        "echo \">> aitodpycocotools GitHub'dan (NO local path!) kuruluyor...\"\n",
        "python -m pip install -v --no-build-isolation \\\n",
        "  \"git+https://github.com/jwwangchn/cocoapi-aitod.git#subdirectory=aitodpycocotools\"\n",
        "\n",
        "echo \">> Kurulum testi:\"\n",
        "python - << 'EOF'\n",
        "import sys, pkg_resources\n",
        "print(\"Python:\", sys.version)\n",
        "try:\n",
        "    import aitodpycocotools\n",
        "    print(\"aitodpycocotools OK:\", aitodpycocotools.__file__)\n",
        "except Exception as e:\n",
        "    print(\"aitodpycocotools IMPORT FAILED:\", e)\n",
        "\n",
        "try:\n",
        "    import yapf\n",
        "    print(\"yapf version:\", pkg_resources.get_distribution(\"yapf\").version)\n",
        "except Exception as e:\n",
        "    print(\"yapf IMPORT FAILED:\", e)\n",
        "EOF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Db17Y85zxzbL",
        "outputId": "b5631bed-14f9-45b9-de66-d9be5dd68312"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python: 3.8.20 (default, Sep  7 2024, 18:35:08) \n",
            "[GCC 11.4.0]\n",
            "aitodpycocotools OK: /content/py38/lib/python3.8/site-packages/aitodpycocotools/__init__.py\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "set -e\n",
        "source /content/py38/bin/activate\n",
        "\n",
        "python - << 'EOF'\n",
        "import sys\n",
        "print(\"Python:\", sys.version)\n",
        "try:\n",
        "    import aitodpycocotools\n",
        "    print(\"aitodpycocotools OK:\", aitodpycocotools.__file__)\n",
        "except Exception as e:\n",
        "    print(\"aitodpycocotools IMPORT FAILED:\", e)\n",
        "EOF\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVlY-3Elah-U",
        "outputId": "ee272f03-f277-420f-b2ea-3195bae86826"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Dataset found at: /content/drive/MyDrive/mmdet_nwdrka/mmdet-nwdrka/data/aitodv2\n",
            "✓ Dataset annotations found\n",
            "✓ Train/val images found\n",
            "\n",
            "Dataset is ready. Config files should point to: /content/drive/MyDrive/mmdet_nwdrka/mmdet-nwdrka/data/aitodv2\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 4: Verify Dataset Location\n",
        "# ============================================================================\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Ensure we're using Python 3.8 venv packages if available\n",
        "if os.path.exists(VENV_PATH):\n",
        "    venv_site_packages = f'{VENV_PATH}/lib/python3.8/site-packages'\n",
        "    if venv_site_packages not in sys.path:\n",
        "        sys.path.insert(0, venv_site_packages)\n",
        "\n",
        "# Verify dataset is available at the expected location\n",
        "if os.path.exists(DATASET_EXTRACTED_PATH):\n",
        "    print(f\"✓ Dataset found at: {DATASET_EXTRACTED_PATH}\")\n",
        "    if os.path.exists(f'{DATASET_EXTRACTED_PATH}/annotations'):\n",
        "        print(\"✓ Dataset annotations found\")\n",
        "    if os.path.exists(f'{DATASET_EXTRACTED_PATH}/trainval'):\n",
        "        print(\"✓ Train/val images found\")\n",
        "    if os.path.exists(f'{DATASET_EXTRACTED_PATH}/test'):\n",
        "        print(\"✓ Test images found\")\n",
        "    print(f\"\\nDataset is ready. Config files should point to: {DATASET_EXTRACTED_PATH}\")\n",
        "else:\n",
        "    print(f\"Note: Dataset not found at {DATASET_EXTRACTED_PATH}\")\n",
        "    print(\"Make sure the dataset is already extracted in the mmdet-nwdrka/data folder\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZoT5Ocg38Ka",
        "outputId": "8e11af61-9896-4f4f-b94a-370ba6c63150"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: yapf==0.30.0 in ./py38/lib/python3.8/site-packages (0.30.0)\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "set -e\n",
        "source /content/py38/bin/activate\n",
        "python -m pip install \"yapf==0.30.0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3YIKB0U54fLd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NP0-DK2vah-V",
        "outputId": "7be206de-370b-4482-8264-68eb77811e8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training...\n",
            "Config: /content/drive/MyDrive/mmdet_nwdrka/mmdet-nwdrka/configs_nwdrka/nwd_rka/aitod_super_faster_r50_iou_1x.py\n",
            "Work dir: /content/drive/MyDrive/outputs/work_dirs/train_aitod_super_faster_r50_iou_1x\n",
            "Using Python: /content/py38/bin/python\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 5: Train\n",
        "# ============================================================================\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Ensure we're using Python 3.8 venv packages if available\n",
        "if os.path.exists(VENV_PATH):\n",
        "    venv_site_packages = f'{VENV_PATH}/lib/python3.8/site-packages'\n",
        "    if venv_site_packages not in sys.path:\n",
        "        sys.path.insert(0, venv_site_packages)\n",
        "\n",
        "# Config file (use as-is, no modifications)\n",
        "CONFIG_FULL = f'{REPO_PATH}/configs_nwdrka/{CONFIG_FILE}'\n",
        "if not os.path.exists(CONFIG_FULL):\n",
        "    print(f\"ERROR: Config file not found at {CONFIG_FULL}\")\n",
        "    print(\"Available configs:\")\n",
        "    !find {REPO_PATH}/configs_nwdrka -name \"*.py\" | head -20\n",
        "else:\n",
        "    # Set work directory\n",
        "    os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
        "    WORK_DIR_OUTPUT = f'{OUTPUT_PATH}/work_dirs'\n",
        "    os.makedirs(WORK_DIR_OUTPUT, exist_ok=True)\n",
        "    TRAIN_WORK_DIR = f'{WORK_DIR_OUTPUT}/train_{os.path.basename(CONFIG_FILE).replace(\".py\", \"\")}'\n",
        "\n",
        "    print(f\"Starting training...\")\n",
        "    print(f\"Config: {CONFIG_FULL}\")\n",
        "    print(f\"Work dir: {TRAIN_WORK_DIR}\")\n",
        "    print(f\"Using Python: {VENV_PYTHON}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWxy1IDioWTv",
        "outputId": "cd88c09c-a3f8-44b7-ea82-3d4192b19aa3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/py38/lib/python3.8/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
            "  warnings.warn(\n",
            "/content/drive/MyDrive/mmdet_nwdrka/mmdet-nwdrka/tools/../mmdet/utils/setup_env.py:38: UserWarning: Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\n",
            "  warnings.warn(\n",
            "/content/drive/MyDrive/mmdet_nwdrka/mmdet-nwdrka/tools/../mmdet/utils/setup_env.py:48: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\n",
            "  warnings.warn(\n",
            "fatal: not a git repository (or any parent up to mount point /content)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "2025-12-27 13:32:21,260 - mmdet - INFO - Environment info:\n",
            "------------------------------------------------------------\n",
            "sys.platform: linux\n",
            "Python: 3.8.20 (default, Sep  7 2024, 18:35:08) [GCC 11.4.0]\n",
            "CUDA available: True\n",
            "GPU 0: NVIDIA L4\n",
            "CUDA_HOME: /usr/local/cuda\n",
            "NVCC: Cuda compilation tools, release 12.5, V12.5.82\n",
            "GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04.2) 11.4.0\n",
            "PyTorch: 1.13.1+cu117\n",
            "PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201402\n",
            "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.7\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
            "  - CuDNN 8.5\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "TorchVision: 0.14.1+cu117\n",
            "OpenCV: 4.12.0\n",
            "MMCV: 1.7.1\n",
            "MMCV Compiler: GCC 9.3\n",
            "MMCV CUDA Compiler: 11.7\n",
            "MMDetection: 2.24.1+\n",
            "------------------------------------------------------------\n",
            "\n",
            "2025-12-27 13:32:22,177 - mmdet - INFO - Distributed training: False\n",
            "2025-12-27 13:32:23,088 - mmdet - INFO - Config:\n",
            "dataset_type = 'AITODv2Dataset'\n",
            "data_root = '/content/drive/MyDrive/mmdet_nwdrka/mmdet-nwdrka/data/aitod_super/'\n",
            "img_norm_cfg = dict(\n",
            "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "    dict(type='Resize', img_scale=(800, 800), keep_ratio=True),\n",
            "    dict(type='RandomFlip', flip_ratio=0.5),\n",
            "    dict(\n",
            "        type='Normalize',\n",
            "        mean=[123.675, 116.28, 103.53],\n",
            "        std=[58.395, 57.12, 57.375],\n",
            "        to_rgb=True),\n",
            "    dict(type='Pad', size_divisor=32),\n",
            "    dict(type='DefaultFormatBundle'),\n",
            "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        type='MultiScaleFlipAug',\n",
            "        img_scale=(800, 800),\n",
            "        flip=False,\n",
            "        transforms=[\n",
            "            dict(type='Resize', keep_ratio=True),\n",
            "            dict(type='RandomFlip'),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_rgb=True),\n",
            "            dict(type='Pad', size_divisor=32),\n",
            "            dict(type='ImageToTensor', keys=['img']),\n",
            "            dict(type='Collect', keys=['img'])\n",
            "        ])\n",
            "]\n",
            "data = dict(\n",
            "    samples_per_gpu=16,\n",
            "    workers_per_gpu=4,\n",
            "    train=dict(\n",
            "        type='AITODv2Dataset',\n",
            "        ann_file=\n",
            "        '/content/drive/MyDrive/mmdet_nwdrka/mmdet-nwdrka/data/aitod_super/annotations/aitodv2_trainval.json',\n",
            "        img_prefix=\n",
            "        '/content/drive/MyDrive/mmdet_nwdrka/mmdet-nwdrka/data/aitod_super/stitched_trainval/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(type='Resize', img_scale=(800, 800), keep_ratio=True),\n",
            "            dict(type='RandomFlip', flip_ratio=0.5),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_rgb=True),\n",
            "            dict(type='Pad', size_divisor=32),\n",
            "            dict(type='DefaultFormatBundle'),\n",
            "            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
            "        ]),\n",
            "    val=dict(\n",
            "        type='AITODv2Dataset',\n",
            "        ann_file=\n",
            "        '/content/drive/MyDrive/mmdet_nwdrka/mmdet-nwdrka/data/aitod_super/annotations/aitod_val.json',\n",
            "        img_prefix=\n",
            "        '/content/drive/MyDrive/mmdet_nwdrka/mmdet-nwdrka/data/aitod_super/stitched_val/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=(800, 800),\n",
            "                flip=False,\n",
            "                transforms=[\n",
            "                    dict(type='Resize', keep_ratio=True),\n",
            "                    dict(type='RandomFlip'),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[123.675, 116.28, 103.53],\n",
            "                        std=[58.395, 57.12, 57.375],\n",
            "                        to_rgb=True),\n",
            "                    dict(type='Pad', size_divisor=32),\n",
            "                    dict(type='ImageToTensor', keys=['img']),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ]),\n",
            "    test=dict(\n",
            "        type='AITODv2Dataset',\n",
            "        ann_file=\n",
            "        '/content/drive/MyDrive/mmdet_nwdrka/mmdet-nwdrka/data/aitod_super/annotations/aitod_val.json',\n",
            "        img_prefix=\n",
            "        '/content/drive/MyDrive/mmdet_nwdrka/mmdet-nwdrka/data/aitod_super/stitched_val/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=(800, 800),\n",
            "                flip=False,\n",
            "                transforms=[\n",
            "                    dict(type='Resize', keep_ratio=True),\n",
            "                    dict(type='RandomFlip'),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[123.675, 116.28, 103.53],\n",
            "                        std=[58.395, 57.12, 57.375],\n",
            "                        to_rgb=True),\n",
            "                    dict(type='Pad', size_divisor=32),\n",
            "                    dict(type='ImageToTensor', keys=['img']),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ]))\n",
            "evaluation = dict(interval=5, metric='bbox')\n",
            "optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
            "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n",
            "lr_config = dict(\n",
            "    policy='step',\n",
            "    warmup='linear',\n",
            "    warmup_iters=500,\n",
            "    warmup_ratio=0.001,\n",
            "    step=[6, 9])\n",
            "runner = dict(type='EpochBasedRunner', max_epochs=10)\n",
            "checkpoint_config = dict(interval=1)\n",
            "log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\n",
            "custom_hooks = [dict(type='NumClassCheckHook')]\n",
            "dist_params = dict(backend='nccl')\n",
            "log_level = 'INFO'\n",
            "load_from = 'workdir/faster_training/epoch_75.pth'\n",
            "resume_from = None\n",
            "workflow = [('train', 1)]\n",
            "opencv_num_threads = 0\n",
            "mp_start_method = 'fork'\n",
            "auto_scale_lr = dict(enable=False, base_batch_size=2)\n",
            "model = dict(\n",
            "    type='FasterRCNN',\n",
            "    pretrained=None,\n",
            "    backbone=dict(\n",
            "        type='ResNet',\n",
            "        depth=50,\n",
            "        num_stages=4,\n",
            "        out_indices=(0, 1, 2, 3),\n",
            "        frozen_stages=4,\n",
            "        norm_cfg=dict(type='BN', requires_grad=True),\n",
            "        norm_eval=True,\n",
            "        style='pytorch'),\n",
            "    neck=dict(\n",
            "        type='FPN',\n",
            "        in_channels=[256, 512, 1024, 2048],\n",
            "        out_channels=256,\n",
            "        num_outs=5),\n",
            "    rpn_head=dict(\n",
            "        type='RPNHead',\n",
            "        in_channels=256,\n",
            "        feat_channels=256,\n",
            "        anchor_generator=dict(\n",
            "            type='AnchorGenerator',\n",
            "            scales=[8],\n",
            "            ratios=[0.5, 1.0, 2.0],\n",
            "            strides=[4, 8, 16, 32, 64]),\n",
            "        bbox_coder=dict(\n",
            "            type='DeltaXYWHBBoxCoder',\n",
            "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
            "        loss_cls=dict(\n",
            "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
            "        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
            "    roi_head=dict(\n",
            "        type='StandardRoIHead',\n",
            "        bbox_roi_extractor=dict(\n",
            "            type='SingleRoIExtractor',\n",
            "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n",
            "            out_channels=256,\n",
            "            featmap_strides=[4, 8, 16, 32]),\n",
            "        bbox_head=dict(\n",
            "            type='Shared2FCBBoxHead',\n",
            "            in_channels=256,\n",
            "            fc_out_channels=1024,\n",
            "            roi_feat_size=7,\n",
            "            num_classes=8,\n",
            "            bbox_coder=dict(\n",
            "                type='DeltaXYWHBBoxCoder',\n",
            "                target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "                target_stds=[0.1, 0.1, 0.2, 0.2]),\n",
            "            reg_class_agnostic=False,\n",
            "            loss_cls=dict(\n",
            "                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
            "            loss_bbox=dict(type='L1Loss', loss_weight=1.0))),\n",
            "    train_cfg=dict(\n",
            "        rpn=dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.7,\n",
            "                neg_iou_thr=0.3,\n",
            "                min_pos_iou=0.3,\n",
            "                match_low_quality=True,\n",
            "                ignore_iof_thr=-1,\n",
            "                gpu_assign_thr=512),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=256,\n",
            "                pos_fraction=0.5,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=False),\n",
            "            allowed_border=-1,\n",
            "            pos_weight=-1,\n",
            "            debug=False),\n",
            "        rpn_proposal=dict(\n",
            "            nms_pre=3000,\n",
            "            max_per_img=3000,\n",
            "            nms=dict(type='nms', iou_threshold=0.7),\n",
            "            min_bbox_size=0),\n",
            "        rcnn=dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.5,\n",
            "                neg_iou_thr=0.5,\n",
            "                min_pos_iou=0.5,\n",
            "                match_low_quality=False,\n",
            "                ignore_iof_thr=-1,\n",
            "                gpu_assign_thr=512),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=512,\n",
            "                pos_fraction=0.25,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=True),\n",
            "            pos_weight=-1,\n",
            "            debug=False)),\n",
            "    test_cfg=dict(\n",
            "        rpn=dict(\n",
            "            nms_pre=3000,\n",
            "            max_per_img=3000,\n",
            "            nms=dict(type='nms', iou_threshold=0.7),\n",
            "            min_bbox_size=0),\n",
            "        rcnn=dict(\n",
            "            score_thr=0.05,\n",
            "            nms=dict(type='nms', iou_threshold=0.5),\n",
            "            max_per_img=3000)))\n",
            "work_dir = '/content/drive/MyDrive/outputs/work_dirs/train_aitod_super_faster_r50_iou_1x'\n",
            "auto_resume = False\n",
            "gpu_ids = [0]\n",
            "\n",
            "2025-12-27 13:32:23,089 - mmdet - INFO - Set random seed to 1304501705, deterministic: False\n",
            "2025-12-27 13:32:23,485 - mmcv - INFO - initialize ResNet with init_cfg [{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]\n",
            "2025-12-27 13:32:23,671 - mmcv - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
            "2025-12-27 13:32:23,673 - mmcv - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
            "2025-12-27 13:32:23,673 - mmcv - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
            "2025-12-27 13:32:23,675 - mmcv - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
            "2025-12-27 13:32:23,676 - mmcv - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
            "2025-12-27 13:32:23,676 - mmcv - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
            "2025-12-27 13:32:23,677 - mmcv - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
            "2025-12-27 13:32:23,679 - mmcv - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
            "2025-12-27 13:32:23,680 - mmcv - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
            "2025-12-27 13:32:23,681 - mmcv - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
            "2025-12-27 13:32:23,682 - mmcv - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
            "2025-12-27 13:32:23,683 - mmcv - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
            "2025-12-27 13:32:23,684 - mmcv - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
            "2025-12-27 13:32:23,687 - mmcv - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
            "2025-12-27 13:32:23,689 - mmcv - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
            "2025-12-27 13:32:23,691 - mmcv - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}\n",
            "2025-12-27 13:32:23,700 - mmcv - INFO - initialize FPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}\n",
            "2025-12-27 13:32:23,725 - mmcv - INFO - initialize RPNHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01}\n",
            "2025-12-27 13:32:23,731 - mmcv - INFO - initialize Shared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'distribution': 'uniform', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]\n",
            "2025-12-27 13:32:23,833 - mmcv - INFO - \n",
            "backbone.conv1.weight - torch.Size([64, 3, 7, 7]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,833 - mmcv - INFO - \n",
            "backbone.bn1.weight - torch.Size([64]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,833 - mmcv - INFO - \n",
            "backbone.bn1.bias - torch.Size([64]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,833 - mmcv - INFO - \n",
            "backbone.layer1.0.conv1.weight - torch.Size([64, 64, 1, 1]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,833 - mmcv - INFO - \n",
            "backbone.layer1.0.bn1.weight - torch.Size([64]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,833 - mmcv - INFO - \n",
            "backbone.layer1.0.bn1.bias - torch.Size([64]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,833 - mmcv - INFO - \n",
            "backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,834 - mmcv - INFO - \n",
            "backbone.layer1.0.bn2.weight - torch.Size([64]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,834 - mmcv - INFO - \n",
            "backbone.layer1.0.bn2.bias - torch.Size([64]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,834 - mmcv - INFO - \n",
            "backbone.layer1.0.conv3.weight - torch.Size([256, 64, 1, 1]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,834 - mmcv - INFO - \n",
            "backbone.layer1.0.bn3.weight - torch.Size([256]): \n",
            "ConstantInit: val=0, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,834 - mmcv - INFO - \n",
            "backbone.layer1.0.bn3.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,834 - mmcv - INFO - \n",
            "backbone.layer1.0.downsample.0.weight - torch.Size([256, 64, 1, 1]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,834 - mmcv - INFO - \n",
            "backbone.layer1.0.downsample.1.weight - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,834 - mmcv - INFO - \n",
            "backbone.layer1.0.downsample.1.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,834 - mmcv - INFO - \n",
            "backbone.layer1.1.conv1.weight - torch.Size([64, 256, 1, 1]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,834 - mmcv - INFO - \n",
            "backbone.layer1.1.bn1.weight - torch.Size([64]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,834 - mmcv - INFO - \n",
            "backbone.layer1.1.bn1.bias - torch.Size([64]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,834 - mmcv - INFO - \n",
            "backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,834 - mmcv - INFO - \n",
            "backbone.layer1.1.bn2.weight - torch.Size([64]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,834 - mmcv - INFO - \n",
            "backbone.layer1.1.bn2.bias - torch.Size([64]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,834 - mmcv - INFO - \n",
            "backbone.layer1.1.conv3.weight - torch.Size([256, 64, 1, 1]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,834 - mmcv - INFO - \n",
            "backbone.layer1.1.bn3.weight - torch.Size([256]): \n",
            "ConstantInit: val=0, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,834 - mmcv - INFO - \n",
            "backbone.layer1.1.bn3.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,834 - mmcv - INFO - \n",
            "backbone.layer1.2.conv1.weight - torch.Size([64, 256, 1, 1]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,834 - mmcv - INFO - \n",
            "backbone.layer1.2.bn1.weight - torch.Size([64]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,834 - mmcv - INFO - \n",
            "backbone.layer1.2.bn1.bias - torch.Size([64]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,834 - mmcv - INFO - \n",
            "backbone.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,834 - mmcv - INFO - \n",
            "backbone.layer1.2.bn2.weight - torch.Size([64]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,834 - mmcv - INFO - \n",
            "backbone.layer1.2.bn2.bias - torch.Size([64]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,834 - mmcv - INFO - \n",
            "backbone.layer1.2.conv3.weight - torch.Size([256, 64, 1, 1]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,834 - mmcv - INFO - \n",
            "backbone.layer1.2.bn3.weight - torch.Size([256]): \n",
            "ConstantInit: val=0, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,834 - mmcv - INFO - \n",
            "backbone.layer1.2.bn3.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,834 - mmcv - INFO - \n",
            "backbone.layer2.0.conv1.weight - torch.Size([128, 256, 1, 1]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,835 - mmcv - INFO - \n",
            "backbone.layer2.0.bn1.weight - torch.Size([128]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,835 - mmcv - INFO - \n",
            "backbone.layer2.0.bn1.bias - torch.Size([128]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,835 - mmcv - INFO - \n",
            "backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,835 - mmcv - INFO - \n",
            "backbone.layer2.0.bn2.weight - torch.Size([128]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,835 - mmcv - INFO - \n",
            "backbone.layer2.0.bn2.bias - torch.Size([128]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,835 - mmcv - INFO - \n",
            "backbone.layer2.0.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,835 - mmcv - INFO - \n",
            "backbone.layer2.0.bn3.weight - torch.Size([512]): \n",
            "ConstantInit: val=0, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,835 - mmcv - INFO - \n",
            "backbone.layer2.0.bn3.bias - torch.Size([512]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,835 - mmcv - INFO - \n",
            "backbone.layer2.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,835 - mmcv - INFO - \n",
            "backbone.layer2.0.downsample.1.weight - torch.Size([512]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,835 - mmcv - INFO - \n",
            "backbone.layer2.0.downsample.1.bias - torch.Size([512]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,835 - mmcv - INFO - \n",
            "backbone.layer2.1.conv1.weight - torch.Size([128, 512, 1, 1]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,835 - mmcv - INFO - \n",
            "backbone.layer2.1.bn1.weight - torch.Size([128]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,835 - mmcv - INFO - \n",
            "backbone.layer2.1.bn1.bias - torch.Size([128]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,835 - mmcv - INFO - \n",
            "backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,835 - mmcv - INFO - \n",
            "backbone.layer2.1.bn2.weight - torch.Size([128]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,835 - mmcv - INFO - \n",
            "backbone.layer2.1.bn2.bias - torch.Size([128]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,835 - mmcv - INFO - \n",
            "backbone.layer2.1.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,835 - mmcv - INFO - \n",
            "backbone.layer2.1.bn3.weight - torch.Size([512]): \n",
            "ConstantInit: val=0, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,835 - mmcv - INFO - \n",
            "backbone.layer2.1.bn3.bias - torch.Size([512]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,835 - mmcv - INFO - \n",
            "backbone.layer2.2.conv1.weight - torch.Size([128, 512, 1, 1]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,835 - mmcv - INFO - \n",
            "backbone.layer2.2.bn1.weight - torch.Size([128]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,835 - mmcv - INFO - \n",
            "backbone.layer2.2.bn1.bias - torch.Size([128]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,835 - mmcv - INFO - \n",
            "backbone.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,835 - mmcv - INFO - \n",
            "backbone.layer2.2.bn2.weight - torch.Size([128]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,835 - mmcv - INFO - \n",
            "backbone.layer2.2.bn2.bias - torch.Size([128]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,835 - mmcv - INFO - \n",
            "backbone.layer2.2.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,835 - mmcv - INFO - \n",
            "backbone.layer2.2.bn3.weight - torch.Size([512]): \n",
            "ConstantInit: val=0, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,836 - mmcv - INFO - \n",
            "backbone.layer2.2.bn3.bias - torch.Size([512]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,836 - mmcv - INFO - \n",
            "backbone.layer2.3.conv1.weight - torch.Size([128, 512, 1, 1]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,836 - mmcv - INFO - \n",
            "backbone.layer2.3.bn1.weight - torch.Size([128]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,836 - mmcv - INFO - \n",
            "backbone.layer2.3.bn1.bias - torch.Size([128]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,836 - mmcv - INFO - \n",
            "backbone.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,836 - mmcv - INFO - \n",
            "backbone.layer2.3.bn2.weight - torch.Size([128]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,836 - mmcv - INFO - \n",
            "backbone.layer2.3.bn2.bias - torch.Size([128]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,836 - mmcv - INFO - \n",
            "backbone.layer2.3.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,836 - mmcv - INFO - \n",
            "backbone.layer2.3.bn3.weight - torch.Size([512]): \n",
            "ConstantInit: val=0, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,836 - mmcv - INFO - \n",
            "backbone.layer2.3.bn3.bias - torch.Size([512]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,836 - mmcv - INFO - \n",
            "backbone.layer3.0.conv1.weight - torch.Size([256, 512, 1, 1]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,836 - mmcv - INFO - \n",
            "backbone.layer3.0.bn1.weight - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,836 - mmcv - INFO - \n",
            "backbone.layer3.0.bn1.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,836 - mmcv - INFO - \n",
            "backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,836 - mmcv - INFO - \n",
            "backbone.layer3.0.bn2.weight - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,836 - mmcv - INFO - \n",
            "backbone.layer3.0.bn2.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,836 - mmcv - INFO - \n",
            "backbone.layer3.0.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,836 - mmcv - INFO - \n",
            "backbone.layer3.0.bn3.weight - torch.Size([1024]): \n",
            "ConstantInit: val=0, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,836 - mmcv - INFO - \n",
            "backbone.layer3.0.bn3.bias - torch.Size([1024]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,836 - mmcv - INFO - \n",
            "backbone.layer3.0.downsample.0.weight - torch.Size([1024, 512, 1, 1]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,836 - mmcv - INFO - \n",
            "backbone.layer3.0.downsample.1.weight - torch.Size([1024]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,836 - mmcv - INFO - \n",
            "backbone.layer3.0.downsample.1.bias - torch.Size([1024]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,836 - mmcv - INFO - \n",
            "backbone.layer3.1.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,836 - mmcv - INFO - \n",
            "backbone.layer3.1.bn1.weight - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,836 - mmcv - INFO - \n",
            "backbone.layer3.1.bn1.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,836 - mmcv - INFO - \n",
            "backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,836 - mmcv - INFO - \n",
            "backbone.layer3.1.bn2.weight - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,837 - mmcv - INFO - \n",
            "backbone.layer3.1.bn2.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,837 - mmcv - INFO - \n",
            "backbone.layer3.1.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,837 - mmcv - INFO - \n",
            "backbone.layer3.1.bn3.weight - torch.Size([1024]): \n",
            "ConstantInit: val=0, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,837 - mmcv - INFO - \n",
            "backbone.layer3.1.bn3.bias - torch.Size([1024]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,837 - mmcv - INFO - \n",
            "backbone.layer3.2.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,881 - mmcv - INFO - \n",
            "backbone.layer3.2.bn1.weight - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,881 - mmcv - INFO - \n",
            "backbone.layer3.2.bn1.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,881 - mmcv - INFO - \n",
            "backbone.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,881 - mmcv - INFO - \n",
            "backbone.layer3.2.bn2.weight - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,881 - mmcv - INFO - \n",
            "backbone.layer3.2.bn2.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,881 - mmcv - INFO - \n",
            "backbone.layer3.2.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,881 - mmcv - INFO - \n",
            "backbone.layer3.2.bn3.weight - torch.Size([1024]): \n",
            "ConstantInit: val=0, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,881 - mmcv - INFO - \n",
            "backbone.layer3.2.bn3.bias - torch.Size([1024]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,881 - mmcv - INFO - \n",
            "backbone.layer3.3.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,881 - mmcv - INFO - \n",
            "backbone.layer3.3.bn1.weight - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,881 - mmcv - INFO - \n",
            "backbone.layer3.3.bn1.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,881 - mmcv - INFO - \n",
            "backbone.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,881 - mmcv - INFO - \n",
            "backbone.layer3.3.bn2.weight - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,881 - mmcv - INFO - \n",
            "backbone.layer3.3.bn2.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,881 - mmcv - INFO - \n",
            "backbone.layer3.3.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,881 - mmcv - INFO - \n",
            "backbone.layer3.3.bn3.weight - torch.Size([1024]): \n",
            "ConstantInit: val=0, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,881 - mmcv - INFO - \n",
            "backbone.layer3.3.bn3.bias - torch.Size([1024]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,881 - mmcv - INFO - \n",
            "backbone.layer3.4.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,881 - mmcv - INFO - \n",
            "backbone.layer3.4.bn1.weight - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,881 - mmcv - INFO - \n",
            "backbone.layer3.4.bn1.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,882 - mmcv - INFO - \n",
            "backbone.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,882 - mmcv - INFO - \n",
            "backbone.layer3.4.bn2.weight - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,882 - mmcv - INFO - \n",
            "backbone.layer3.4.bn2.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,882 - mmcv - INFO - \n",
            "backbone.layer3.4.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,882 - mmcv - INFO - \n",
            "backbone.layer3.4.bn3.weight - torch.Size([1024]): \n",
            "ConstantInit: val=0, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,882 - mmcv - INFO - \n",
            "backbone.layer3.4.bn3.bias - torch.Size([1024]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,882 - mmcv - INFO - \n",
            "backbone.layer3.5.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,882 - mmcv - INFO - \n",
            "backbone.layer3.5.bn1.weight - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,882 - mmcv - INFO - \n",
            "backbone.layer3.5.bn1.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,882 - mmcv - INFO - \n",
            "backbone.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,882 - mmcv - INFO - \n",
            "backbone.layer3.5.bn2.weight - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,882 - mmcv - INFO - \n",
            "backbone.layer3.5.bn2.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,882 - mmcv - INFO - \n",
            "backbone.layer3.5.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,882 - mmcv - INFO - \n",
            "backbone.layer3.5.bn3.weight - torch.Size([1024]): \n",
            "ConstantInit: val=0, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,882 - mmcv - INFO - \n",
            "backbone.layer3.5.bn3.bias - torch.Size([1024]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,882 - mmcv - INFO - \n",
            "backbone.layer4.0.conv1.weight - torch.Size([512, 1024, 1, 1]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,882 - mmcv - INFO - \n",
            "backbone.layer4.0.bn1.weight - torch.Size([512]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,882 - mmcv - INFO - \n",
            "backbone.layer4.0.bn1.bias - torch.Size([512]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,882 - mmcv - INFO - \n",
            "backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,882 - mmcv - INFO - \n",
            "backbone.layer4.0.bn2.weight - torch.Size([512]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,882 - mmcv - INFO - \n",
            "backbone.layer4.0.bn2.bias - torch.Size([512]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,882 - mmcv - INFO - \n",
            "backbone.layer4.0.conv3.weight - torch.Size([2048, 512, 1, 1]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,882 - mmcv - INFO - \n",
            "backbone.layer4.0.bn3.weight - torch.Size([2048]): \n",
            "ConstantInit: val=0, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,882 - mmcv - INFO - \n",
            "backbone.layer4.0.bn3.bias - torch.Size([2048]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,882 - mmcv - INFO - \n",
            "backbone.layer4.0.downsample.0.weight - torch.Size([2048, 1024, 1, 1]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,882 - mmcv - INFO - \n",
            "backbone.layer4.0.downsample.1.weight - torch.Size([2048]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,882 - mmcv - INFO - \n",
            "backbone.layer4.0.downsample.1.bias - torch.Size([2048]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,882 - mmcv - INFO - \n",
            "backbone.layer4.1.conv1.weight - torch.Size([512, 2048, 1, 1]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,883 - mmcv - INFO - \n",
            "backbone.layer4.1.bn1.weight - torch.Size([512]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,883 - mmcv - INFO - \n",
            "backbone.layer4.1.bn1.bias - torch.Size([512]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,883 - mmcv - INFO - \n",
            "backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,883 - mmcv - INFO - \n",
            "backbone.layer4.1.bn2.weight - torch.Size([512]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,883 - mmcv - INFO - \n",
            "backbone.layer4.1.bn2.bias - torch.Size([512]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,883 - mmcv - INFO - \n",
            "backbone.layer4.1.conv3.weight - torch.Size([2048, 512, 1, 1]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,883 - mmcv - INFO - \n",
            "backbone.layer4.1.bn3.weight - torch.Size([2048]): \n",
            "ConstantInit: val=0, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,883 - mmcv - INFO - \n",
            "backbone.layer4.1.bn3.bias - torch.Size([2048]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,883 - mmcv - INFO - \n",
            "backbone.layer4.2.conv1.weight - torch.Size([512, 2048, 1, 1]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,883 - mmcv - INFO - \n",
            "backbone.layer4.2.bn1.weight - torch.Size([512]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,883 - mmcv - INFO - \n",
            "backbone.layer4.2.bn1.bias - torch.Size([512]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,883 - mmcv - INFO - \n",
            "backbone.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,883 - mmcv - INFO - \n",
            "backbone.layer4.2.bn2.weight - torch.Size([512]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,883 - mmcv - INFO - \n",
            "backbone.layer4.2.bn2.bias - torch.Size([512]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,883 - mmcv - INFO - \n",
            "backbone.layer4.2.conv3.weight - torch.Size([2048, 512, 1, 1]): \n",
            "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,883 - mmcv - INFO - \n",
            "backbone.layer4.2.bn3.weight - torch.Size([2048]): \n",
            "ConstantInit: val=0, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,883 - mmcv - INFO - \n",
            "backbone.layer4.2.bn3.bias - torch.Size([2048]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,883 - mmcv - INFO - \n",
            "neck.lateral_convs.0.conv.weight - torch.Size([256, 256, 1, 1]): \n",
            "XavierInit: gain=1, distribution=uniform, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,883 - mmcv - INFO - \n",
            "neck.lateral_convs.0.conv.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,883 - mmcv - INFO - \n",
            "neck.lateral_convs.1.conv.weight - torch.Size([256, 512, 1, 1]): \n",
            "XavierInit: gain=1, distribution=uniform, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,883 - mmcv - INFO - \n",
            "neck.lateral_convs.1.conv.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,883 - mmcv - INFO - \n",
            "neck.lateral_convs.2.conv.weight - torch.Size([256, 1024, 1, 1]): \n",
            "XavierInit: gain=1, distribution=uniform, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,883 - mmcv - INFO - \n",
            "neck.lateral_convs.2.conv.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,883 - mmcv - INFO - \n",
            "neck.lateral_convs.3.conv.weight - torch.Size([256, 2048, 1, 1]): \n",
            "XavierInit: gain=1, distribution=uniform, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,883 - mmcv - INFO - \n",
            "neck.lateral_convs.3.conv.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,883 - mmcv - INFO - \n",
            "neck.fpn_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): \n",
            "XavierInit: gain=1, distribution=uniform, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,883 - mmcv - INFO - \n",
            "neck.fpn_convs.0.conv.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,884 - mmcv - INFO - \n",
            "neck.fpn_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): \n",
            "XavierInit: gain=1, distribution=uniform, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,884 - mmcv - INFO - \n",
            "neck.fpn_convs.1.conv.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,884 - mmcv - INFO - \n",
            "neck.fpn_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): \n",
            "XavierInit: gain=1, distribution=uniform, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,884 - mmcv - INFO - \n",
            "neck.fpn_convs.2.conv.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,884 - mmcv - INFO - \n",
            "neck.fpn_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): \n",
            "XavierInit: gain=1, distribution=uniform, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,884 - mmcv - INFO - \n",
            "neck.fpn_convs.3.conv.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of FasterRCNN  \n",
            " \n",
            "2025-12-27 13:32:23,884 - mmcv - INFO - \n",
            "rpn_head.rpn_conv.weight - torch.Size([256, 256, 3, 3]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,884 - mmcv - INFO - \n",
            "rpn_head.rpn_conv.bias - torch.Size([256]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,884 - mmcv - INFO - \n",
            "rpn_head.rpn_cls.weight - torch.Size([3, 256, 1, 1]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,884 - mmcv - INFO - \n",
            "rpn_head.rpn_cls.bias - torch.Size([3]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,884 - mmcv - INFO - \n",
            "rpn_head.rpn_reg.weight - torch.Size([12, 256, 1, 1]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,884 - mmcv - INFO - \n",
            "rpn_head.rpn_reg.bias - torch.Size([12]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,884 - mmcv - INFO - \n",
            "roi_head.bbox_head.fc_cls.weight - torch.Size([9, 1024]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,884 - mmcv - INFO - \n",
            "roi_head.bbox_head.fc_cls.bias - torch.Size([9]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,884 - mmcv - INFO - \n",
            "roi_head.bbox_head.fc_reg.weight - torch.Size([32, 1024]): \n",
            "NormalInit: mean=0, std=0.001, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,884 - mmcv - INFO - \n",
            "roi_head.bbox_head.fc_reg.bias - torch.Size([32]): \n",
            "NormalInit: mean=0, std=0.001, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,884 - mmcv - INFO - \n",
            "roi_head.bbox_head.shared_fcs.0.weight - torch.Size([1024, 12544]): \n",
            "XavierInit: gain=1, distribution=uniform, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,884 - mmcv - INFO - \n",
            "roi_head.bbox_head.shared_fcs.0.bias - torch.Size([1024]): \n",
            "XavierInit: gain=1, distribution=uniform, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,884 - mmcv - INFO - \n",
            "roi_head.bbox_head.shared_fcs.1.weight - torch.Size([1024, 1024]): \n",
            "XavierInit: gain=1, distribution=uniform, bias=0 \n",
            " \n",
            "2025-12-27 13:32:23,884 - mmcv - INFO - \n",
            "roi_head.bbox_head.shared_fcs.1.bias - torch.Size([1024]): \n",
            "XavierInit: gain=1, distribution=uniform, bias=0 \n",
            " \n",
            "loading annotations into memory...\n",
            "Done (t=3.52s)\n",
            "creating index...\n",
            "index created!\n",
            "fatal: not a git repository (or any parent up to mount point /content)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "2025-12-27 13:32:28,975 - mmdet - INFO - Automatic scaling of learning rate (LR) has been disabled.\n",
            "loading annotations into memory...\n",
            "Done (t=0.45s)\n",
            "creating index...\n",
            "index created!\n",
            "2025-12-27 13:32:29,498 - mmdet - INFO - load checkpoint from local path: workdir/faster_training/epoch_75.pth\n",
            "2025-12-27 13:32:43,354 - mmdet - INFO - Start running, host: root@395da353345b, work_dir: /content/drive/MyDrive/outputs/work_dirs/train_aitod_super_faster_r50_iou_1x\n",
            "2025-12-27 13:32:43,354 - mmdet - INFO - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
            "(NORMAL      ) CheckpointHook                     \n",
            "(LOW         ) EvalHook                           \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
            "(NORMAL      ) NumClassCheckHook                  \n",
            "(LOW         ) IterTimerHook                      \n",
            "(LOW         ) EvalHook                           \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
            "(LOW         ) IterTimerHook                      \n",
            "(LOW         ) EvalHook                           \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(ABOVE_NORMAL) OptimizerHook                      \n",
            "(NORMAL      ) CheckpointHook                     \n",
            "(LOW         ) IterTimerHook                      \n",
            "(LOW         ) EvalHook                           \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) CheckpointHook                     \n",
            "(LOW         ) EvalHook                           \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) NumClassCheckHook                  \n",
            "(LOW         ) IterTimerHook                      \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(LOW         ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(LOW         ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_run:\n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "2025-12-27 13:32:43,355 - mmdet - INFO - workflow: [('train', 1)], max: 10 epochs\n",
            "2025-12-27 13:32:43,355 - mmdet - INFO - Checkpoints will be saved to /content/drive/MyDrive/outputs/work_dirs/train_aitod_super_faster_r50_iou_1x by HardDiskBackend.\n",
            "2025-12-27 13:33:55,994 - mmdet - INFO - Epoch [1][50/877]\tlr: 9.890e-04, eta: 3:30:58, time: 1.452, data_time: 0.093, memory: 7855, loss_rpn_cls: 0.1079, loss_rpn_bbox: 0.0554, loss_cls: 0.1270, acc: 95.4380, loss_bbox: 0.1911, loss: 0.4815, grad_norm: 0.5558\n",
            "2025-12-27 13:35:05,234 - mmdet - INFO - Epoch [1][100/877]\tlr: 1.988e-03, eta: 3:24:55, time: 1.385, data_time: 0.030, memory: 7855, loss_rpn_cls: 0.0976, loss_rpn_bbox: 0.0438, loss_cls: 0.1276, acc: 95.3967, loss_bbox: 0.1898, loss: 0.4588, grad_norm: 0.5126\n",
            "2025-12-27 13:35:45,945 - mmcv - INFO - [LoadImageFromFile] Image file not found, skip this sample: /content/drive/MyDrive/mmdet_nwdrka/mmdet-nwdrka/data/aitod_super/stitched_trainval/03615.png\n",
            "2025-12-27 13:36:11,211 - mmdet - INFO - Epoch [1][150/877]\tlr: 2.987e-03, eta: 3:19:01, time: 1.320, data_time: 0.030, memory: 7855, loss_rpn_cls: 0.0975, loss_rpn_bbox: 0.0392, loss_cls: 0.1235, acc: 95.5303, loss_bbox: 0.1857, loss: 0.4459, grad_norm: 0.5009\n",
            "2025-12-27 13:37:21,452 - mmdet - INFO - Epoch [1][200/877]\tlr: 3.986e-03, eta: 3:18:33, time: 1.405, data_time: 0.031, memory: 7855, loss_rpn_cls: 0.0787, loss_rpn_bbox: 0.0308, loss_cls: 0.1160, acc: 95.9102, loss_bbox: 0.1581, loss: 0.3835, grad_norm: 0.4816\n",
            "2025-12-27 13:38:27,698 - mmdet - INFO - Epoch [1][250/877]\tlr: 4.985e-03, eta: 3:15:33, time: 1.325, data_time: 0.031, memory: 7855, loss_rpn_cls: 0.0864, loss_rpn_bbox: 0.0322, loss_cls: 0.1156, acc: 95.8921, loss_bbox: 0.1606, loss: 0.3949, grad_norm: 0.4983\n",
            "2025-12-27 13:39:34,306 - mmdet - INFO - Epoch [1][300/877]\tlr: 5.984e-03, eta: 3:13:20, time: 1.332, data_time: 0.032, memory: 7855, loss_rpn_cls: 0.0930, loss_rpn_bbox: 0.0382, loss_cls: 0.1171, acc: 95.7266, loss_bbox: 0.1626, loss: 0.4109, grad_norm: 0.5255\n",
            "2025-12-27 13:40:43,979 - mmdet - INFO - Epoch [1][350/877]\tlr: 6.983e-03, eta: 3:12:40, time: 1.393, data_time: 0.032, memory: 7855, loss_rpn_cls: 0.0787, loss_rpn_bbox: 0.0311, loss_cls: 0.1057, acc: 96.3071, loss_bbox: 0.1356, loss: 0.3510, grad_norm: 0.5351\n",
            "2025-12-27 13:41:52,772 - mmdet - INFO - Epoch [1][400/877]\tlr: 7.982e-03, eta: 3:11:35, time: 1.376, data_time: 0.032, memory: 7855, loss_rpn_cls: 0.0894, loss_rpn_bbox: 0.0342, loss_cls: 0.1022, acc: 96.4031, loss_bbox: 0.1314, loss: 0.3572, grad_norm: 0.5023\n",
            "2025-12-27 13:43:03,094 - mmdet - INFO - Epoch [1][450/877]\tlr: 8.981e-03, eta: 3:10:57, time: 1.406, data_time: 0.031, memory: 7855, loss_rpn_cls: 0.0902, loss_rpn_bbox: 0.0338, loss_cls: 0.1029, acc: 96.3010, loss_bbox: 0.1378, loss: 0.3647, grad_norm: 0.5168\n",
            "2025-12-27 13:44:12,947 - mmdet - INFO - Epoch [1][500/877]\tlr: 9.980e-03, eta: 3:10:04, time: 1.397, data_time: 0.032, memory: 7855, loss_rpn_cls: 0.0869, loss_rpn_bbox: 0.0309, loss_cls: 0.0986, acc: 96.5598, loss_bbox: 0.1250, loss: 0.3413, grad_norm: 0.5045\n",
            "2025-12-27 13:45:23,023 - mmdet - INFO - Epoch [1][550/877]\tlr: 1.000e-02, eta: 3:09:12, time: 1.402, data_time: 0.031, memory: 7855, loss_rpn_cls: 0.0796, loss_rpn_bbox: 0.0304, loss_cls: 0.0977, acc: 96.6167, loss_bbox: 0.1219, loss: 0.3296, grad_norm: 0.5263\n",
            "2025-12-27 13:46:33,658 - mmdet - INFO - Epoch [1][600/877]\tlr: 1.000e-02, eta: 3:08:25, time: 1.413, data_time: 0.032, memory: 7855, loss_rpn_cls: 0.0918, loss_rpn_bbox: 0.0340, loss_cls: 0.1030, acc: 96.3940, loss_bbox: 0.1266, loss: 0.3554, grad_norm: 0.5095\n",
            "2025-12-27 13:47:38,985 - mmdet - INFO - Epoch [1][650/877]\tlr: 1.000e-02, eta: 3:06:27, time: 1.307, data_time: 0.031, memory: 7855, loss_rpn_cls: 0.0875, loss_rpn_bbox: 0.0348, loss_cls: 0.0972, acc: 96.6055, loss_bbox: 0.1232, loss: 0.3427, grad_norm: 0.4759\n",
            "2025-12-27 13:48:47,319 - mmdet - INFO - Epoch [1][700/877]\tlr: 1.000e-02, eta: 3:05:12, time: 1.367, data_time: 0.032, memory: 7855, loss_rpn_cls: 0.0815, loss_rpn_bbox: 0.0305, loss_cls: 0.0953, acc: 96.7229, loss_bbox: 0.1154, loss: 0.3228, grad_norm: 0.5046\n",
            "2025-12-27 13:49:59,279 - mmdet - INFO - Epoch [1][750/877]\tlr: 1.000e-02, eta: 3:04:36, time: 1.439, data_time: 0.033, memory: 7855, loss_rpn_cls: 0.0864, loss_rpn_bbox: 0.0317, loss_cls: 0.0937, acc: 96.7585, loss_bbox: 0.1170, loss: 0.3288, grad_norm: 0.4770\n",
            "2025-12-27 13:51:06,894 - mmdet - INFO - Epoch [1][800/877]\tlr: 1.000e-02, eta: 3:03:13, time: 1.352, data_time: 0.032, memory: 7855, loss_rpn_cls: 0.0800, loss_rpn_bbox: 0.0290, loss_cls: 0.0863, acc: 96.9902, loss_bbox: 0.1069, loss: 0.3023, grad_norm: 0.4561\n",
            "2025-12-27 13:52:17,402 - mmdet - INFO - Epoch [1][850/877]\tlr: 1.000e-02, eta: 3:02:18, time: 1.410, data_time: 0.032, memory: 7855, loss_rpn_cls: 0.0779, loss_rpn_bbox: 0.0286, loss_cls: 0.0905, acc: 96.8184, loss_bbox: 0.1143, loss: 0.3112, grad_norm: 0.4453\n",
            "2025-12-27 13:52:53,819 - mmdet - INFO - Saving checkpoint at 1 epochs\n",
            "2025-12-27 13:54:06,152 - mmdet - INFO - Epoch [2][50/877]\tlr: 1.000e-02, eta: 2:55:37, time: 1.430, data_time: 0.098, memory: 7855, loss_rpn_cls: 0.0808, loss_rpn_bbox: 0.0286, loss_cls: 0.0864, acc: 96.9548, loss_bbox: 0.1076, loss: 0.3035, grad_norm: 0.4554\n",
            "2025-12-27 13:55:14,735 - mmdet - INFO - Epoch [2][100/877]\tlr: 1.000e-02, eta: 2:54:41, time: 1.372, data_time: 0.031, memory: 7855, loss_rpn_cls: 0.0782, loss_rpn_bbox: 0.0309, loss_cls: 0.0871, acc: 96.9326, loss_bbox: 0.1113, loss: 0.3075, grad_norm: 0.4738\n",
            "2025-12-27 13:56:22,100 - mmdet - INFO - Epoch [2][150/877]\tlr: 1.000e-02, eta: 2:53:35, time: 1.347, data_time: 0.032, memory: 7855, loss_rpn_cls: 0.0856, loss_rpn_bbox: 0.0324, loss_cls: 0.0876, acc: 96.7949, loss_bbox: 0.1151, loss: 0.3208, grad_norm: 0.4560\n",
            "2025-12-27 13:57:32,638 - mmdet - INFO - Epoch [2][200/877]\tlr: 1.000e-02, eta: 2:52:51, time: 1.411, data_time: 0.031, memory: 7855, loss_rpn_cls: 0.0793, loss_rpn_bbox: 0.0283, loss_cls: 0.0851, acc: 97.0332, loss_bbox: 0.1083, loss: 0.3010, grad_norm: 0.4554\n",
            "2025-12-27 13:58:40,758 - mmdet - INFO - Epoch [2][250/877]\tlr: 1.000e-02, eta: 2:51:48, time: 1.362, data_time: 0.032, memory: 7855, loss_rpn_cls: 0.0821, loss_rpn_bbox: 0.0312, loss_cls: 0.1010, acc: 96.4153, loss_bbox: 0.1222, loss: 0.3366, grad_norm: 0.5195\n",
            "2025-12-27 13:59:49,034 - mmdet - INFO - Epoch [2][300/877]\tlr: 1.000e-02, eta: 2:50:46, time: 1.366, data_time: 0.031, memory: 7855, loss_rpn_cls: 0.0803, loss_rpn_bbox: 0.0287, loss_cls: 0.0824, acc: 97.1316, loss_bbox: 0.1023, loss: 0.2937, grad_norm: 0.4666\n",
            "2025-12-27 14:00:58,442 - mmdet - INFO - Epoch [2][350/877]\tlr: 1.000e-02, eta: 2:49:51, time: 1.388, data_time: 0.032, memory: 7855, loss_rpn_cls: 0.0799, loss_rpn_bbox: 0.0300, loss_cls: 0.0810, acc: 97.0874, loss_bbox: 0.1042, loss: 0.2951, grad_norm: 0.4464\n",
            "2025-12-27 14:02:04,176 - mmdet - INFO - Epoch [2][400/877]\tlr: 1.000e-02, eta: 2:48:33, time: 1.315, data_time: 0.032, memory: 7855, loss_rpn_cls: 0.0816, loss_rpn_bbox: 0.0296, loss_cls: 0.0895, acc: 96.8882, loss_bbox: 0.1133, loss: 0.3140, grad_norm: 0.4771\n",
            "2025-12-27 14:02:16,407 - mmcv - INFO - [LoadImageFromFile] Image file not found, skip this sample: /content/drive/MyDrive/mmdet_nwdrka/mmdet-nwdrka/data/aitod_super/stitched_trainval/03615.png\n",
            "2025-12-27 14:03:12,909 - mmdet - INFO - Epoch [2][450/877]\tlr: 1.000e-02, eta: 2:47:32, time: 1.375, data_time: 0.033, memory: 7855, loss_rpn_cls: 0.0826, loss_rpn_bbox: 0.0295, loss_cls: 0.0841, acc: 97.0713, loss_bbox: 0.1041, loss: 0.3003, grad_norm: 0.4658\n",
            "2025-12-27 14:04:23,811 - mmdet - INFO - Epoch [2][500/877]\tlr: 1.000e-02, eta: 2:46:43, time: 1.418, data_time: 0.032, memory: 7855, loss_rpn_cls: 0.0827, loss_rpn_bbox: 0.0293, loss_cls: 0.0862, acc: 96.9719, loss_bbox: 0.1072, loss: 0.3055, grad_norm: 0.4465\n"
          ]
        }
      ],
      "source": [
        "# Train using config directly (no modifications) with Python 3.8 venv\n",
        "!{VENV_ACTIVATE} && cd {REPO_PATH} && python tools/train.py configs_nwdrka/{CONFIG_FILE} --work-dir {TRAIN_WORK_DIR}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEg2X4Geka78",
        "outputId": "4ca4cd5b-d0dd-43ac-e9d7-bac120e9e042"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[\"python: can't open file 'tools/train.py': [Errno 2] No such file or directory\"]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        " # Train using config directly (no modifications)\n",
        "!!source /content/py38/bin/activate && python tools/train.py configs_nwdrka/nwd_rka/aitod_super_faster_r50_nwdrka_1x.py --work-dir /content/drive/MyDrive/outputs/work_dirs/train_aitod_super_faster_r50_nwdrka_1x --gpu-ids 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlrRRb0Wah-V",
        "outputId": "360378ba-fe05-4ddb-e2c1-2a44c5b0304b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No checkpoint found for testing\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 6: Test/Evaluate\n",
        "# ============================================================================\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# Find latest checkpoint\n",
        "checkpoint_files = glob.glob(f'{TRAIN_WORK_DIR}/*.pth')\n",
        "if checkpoint_files:\n",
        "    checkpoint_files.sort(key=os.path.getmtime, reverse=True)\n",
        "    LATEST_CHECKPOINT = checkpoint_files[0]\n",
        "    print(f\"Using checkpoint: {LATEST_CHECKPOINT}\")\n",
        "\n",
        "    # Test\n",
        "    TEST_WORK_DIR = f'{WORK_DIR_OUTPUT}/test_{os.path.basename(CONFIG_FILE).replace(\".py\", \"\")}'\n",
        "    os.makedirs(TEST_WORK_DIR, exist_ok=True)\n",
        "\n",
        "    # Use original config file (no modifications) with Python 3.8 venv\n",
        "    !{VENV_ACTIVATE} && cd {REPO_PATH} && python tools/test.py configs_nwdrka/{CONFIG_FILE} \\\n",
        "        {LATEST_CHECKPOINT} \\\n",
        "        --work-dir {TEST_WORK_DIR} \\\n",
        "        --eval bbox \\\n",
        "        --gpu-id 0 \\\n",
        "        --out {TEST_WORK_DIR}/results.pkl\n",
        "\n",
        "    print(f\"\\nTesting completed! Results in: {TEST_WORK_DIR}\")\n",
        "else:\n",
        "    print(\"No checkpoint found for testing\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2O6BEcKf_6ID",
        "outputId": "7f116288-1b60-456a-bea1-b66702c23574"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "checkpoint_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LmP8wve-ah-W"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# CELL 7: Verify Outputs in Drive\n",
        "# ============================================================================\n",
        "import os\n",
        "import glob\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"OUTPUT SUMMARY\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\nOutputs saved to Google Drive:\")\n",
        "print(f\"  Training outputs: {TRAIN_WORK_DIR}\")\n",
        "\n",
        "if os.path.exists(f'{WORK_DIR_OUTPUT}/test_{os.path.basename(CONFIG_FILE).replace(\".py\", \"\")}'):\n",
        "    print(f\"  Test outputs: {WORK_DIR_OUTPUT}/test_{os.path.basename(CONFIG_FILE).replace(\".py\", \"\")}\")\n",
        "\n",
        "# List checkpoints\n",
        "checkpoints = glob.glob(f'{TRAIN_WORK_DIR}/*.pth')\n",
        "if checkpoints:\n",
        "    print(f\"\\nFound {len(checkpoints)} checkpoint(s):\")\n",
        "    for ckpt in sorted(checkpoints, key=os.path.getmtime, reverse=True)[:5]:  # Show first 5\n",
        "        size_mb = os.path.getsize(ckpt) / (1024 * 1024)\n",
        "        mtime = os.path.getmtime(ckpt)\n",
        "        from datetime import datetime\n",
        "        mtime_str = datetime.fromtimestamp(mtime).strftime('%Y-%m-%d %H:%M:%S')\n",
        "        print(f\"  {os.path.basename(ckpt)} ({size_mb:.1f} MB, {mtime_str})\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"All outputs are saved in your Google Drive!\")\n",
        "print(\"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRRjfmTSah-W"
      },
      "source": [
        "## Additional Notes:\n",
        "\n",
        "### To Resume Training:\n",
        "Modify CELL 5 to add `--resume-from {checkpoint_path}` to the training command.\n",
        "\n",
        "### To Use a Different Checkpoint for Testing:\n",
        "Modify CELL 6 to specify a different checkpoint path instead of using `LATEST_CHECKPOINT`.\n",
        "\n",
        "### To Adjust Training Parameters:\n",
        "You can modify the config file or add command-line arguments in CELL 5:\n",
        "- `--resume-from`: Resume from a checkpoint\n",
        "- `--auto-resume`: Auto-resume from latest checkpoint\n",
        "- `--no-validate`: Skip validation during training\n",
        "\n",
        "### Memory Issues:\n",
        "If you run out of memory, reduce batch size in the config file by modifying `samples_per_gpu` in the dataset configuration.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYAMKU2gIHXh"
      },
      "source": [
        "## TESTİNG WİTH VİSUALİZATİON İMAGE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCcrNQb5HWOi",
        "outputId": "35183483-52ec-4179-e7f1-e1170374dba5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved script to: /content/drive/MyDrive/mmdet_nwdrka/mmdet-nwdrka/infer_batch.py\n"
          ]
        }
      ],
      "source": [
        "script_path = \"/content/drive/MyDrive/mmdet_nwdrka/mmdet-nwdrka/infer_batch.py\"\n",
        "\n",
        "script_code = r'''\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import glob\n",
        "\n",
        "# -------------------- USER PATHS --------------------\n",
        "MMDET_REPO_ROOT = r\"/content/drive/MyDrive/mmdet_nwdrka/mmdet-nwdrka\"\n",
        "CFG_PATH        = r\"/content/drive/MyDrive/outputs/work_dirs/train_aitod_super_faster_r50_csam_nwdrka_1x/aitod_super_faster_r50_csam_nwdrka_1x.py\"\n",
        "CKPT_PATH       = r\"/content/drive/MyDrive/outputs/work_dirs/train_aitod_super_faster_r50_csam_nwdrka_1x/epoch_10.pth\"\n",
        "\n",
        "# Tek resim yerine KLASÖR\n",
        "IMG_DIR         = r\"/content/drive/MyDrive/mmdet_nwdrka/mmdet-nwdrka/data/aitod_super/stitched_val\"  # <--- klasör yolu\n",
        "OUT_DIR         = r\"/content/drive/MyDrive/mmdet_nwdrka/mmdet-nwdrka/data/aitod_super/stitched_val_pred_nwdrka_normal\"\n",
        "\n",
        "SCORE_THR       = 0.80\n",
        "DEVICE          = \"cuda:0\"   # ya da \"cuda\" / \"cpu\"\n",
        "\n",
        "# -------------------- ENV SETUP --------------------\n",
        "MMDET_REPO_ROOT = Path(MMDET_REPO_ROOT).expanduser().resolve()\n",
        "assert MMDET_REPO_ROOT.exists(), f\"Repo root does not exist: {MMDET_REPO_ROOT}\"\n",
        "\n",
        "if str(MMDET_REPO_ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(MMDET_REPO_ROOT))\n",
        "\n",
        "os.chdir(MMDET_REPO_ROOT)\n",
        "\n",
        "CFG_PATH  = str(Path(CFG_PATH).expanduser().resolve())\n",
        "CKPT_PATH = str(Path(CKPT_PATH).expanduser().resolve())\n",
        "IMG_DIR   = str(Path(IMG_DIR).expanduser().resolve())\n",
        "OUT_DIR   = str(Path(OUT_DIR).expanduser().resolve())\n",
        "\n",
        "assert os.path.isfile(CFG_PATH),  f\"Config not found: {CFG_PATH}\"\n",
        "assert os.path.isfile(CKPT_PATH), f\"Checkpoint not found: {CKPT_PATH}\"\n",
        "assert os.path.isdir(IMG_DIR),    f\"Image folder not found: {IMG_DIR}\"\n",
        "\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "# -------------------- IMPORTS (MMDet 2.x) --------------------\n",
        "from mmdet.apis import init_detector, inference_detector\n",
        "import mmcv\n",
        "\n",
        "# -------------------- MODEL INIT --------------------\n",
        "model = init_detector(CFG_PATH, CKPT_PATH, device=DEVICE)\n",
        "\n",
        "# -------------------- BATCH INFERENCE --------------------\n",
        "# Desteklediğin uzantıları ekleyebilirsin\n",
        "img_extensions = [\"*.jpg\", \"*.jpeg\", \"*.png\", \"*.bmp\", \"*.tif\", \"*.tiff\"]\n",
        "\n",
        "img_paths = []\n",
        "for ext in img_extensions:\n",
        "    img_paths.extend(glob.glob(os.path.join(IMG_DIR, ext)))\n",
        "\n",
        "img_paths = sorted(img_paths)\n",
        "print(f\"Found {len(img_paths)} images under {IMG_DIR}\")\n",
        "\n",
        "for img_path in img_paths:\n",
        "    img_name = os.path.basename(img_path)\n",
        "    out_file = os.path.join(OUT_DIR, img_name)\n",
        "\n",
        "    # Inference\n",
        "    result = inference_detector(model, img_path)\n",
        "\n",
        "    # MMDet 2.26: show_result imzası:\n",
        "    # show_result(img, result, score_thr=0.3, show=False, win_name='', wait_time=0, out_file=None)\n",
        "    model.show_result(\n",
        "        img_path,\n",
        "        result,\n",
        "        score_thr=SCORE_THR,\n",
        "        show=False,          # Colab'de pop-up istemiyoruz\n",
        "        out_file=out_file,   # çıktı görüntü yolu\n",
        "    )\n",
        "\n",
        "    print(f\"[OK] Saved: {out_file}\")\n",
        "\n",
        "print(\"All done.\")\n",
        "'''\n",
        "\n",
        "with open(script_path, \"w\") as f:\n",
        "    f.write(script_code)\n",
        "\n",
        "print(\"Saved script to:\", script_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ER9Kc3hY4Bfp",
        "outputId": "956f2b68-047f-4f1b-9d7a-1f4a18126183"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplotlib_inline in /content/py38/lib/python3.8/site-packages (0.1.7)\n",
            "Requirement already satisfied: IPython in /content/py38/lib/python3.8/site-packages (8.12.3)\n",
            "Requirement already satisfied: traitlets in /content/py38/lib/python3.8/site-packages (from matplotlib_inline) (5.14.3)\n",
            "Requirement already satisfied: backcall in /content/py38/lib/python3.8/site-packages (from IPython) (0.2.0)\n",
            "Requirement already satisfied: decorator in /content/py38/lib/python3.8/site-packages (from IPython) (5.2.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /content/py38/lib/python3.8/site-packages (from IPython) (0.19.2)\n",
            "Requirement already satisfied: pickleshare in /content/py38/lib/python3.8/site-packages (from IPython) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /content/py38/lib/python3.8/site-packages (from IPython) (3.0.52)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /content/py38/lib/python3.8/site-packages (from IPython) (2.19.2)\n",
            "Requirement already satisfied: stack-data in /content/py38/lib/python3.8/site-packages (from IPython) (0.6.3)\n",
            "Requirement already satisfied: typing-extensions in /content/py38/lib/python3.8/site-packages (from IPython) (4.13.2)\n",
            "Requirement already satisfied: pexpect>4.3 in /content/py38/lib/python3.8/site-packages (from IPython) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /content/py38/lib/python3.8/site-packages (from jedi>=0.16->IPython) (0.8.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /content/py38/lib/python3.8/site-packages (from pexpect>4.3->IPython) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /content/py38/lib/python3.8/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->IPython) (0.2.14)\n",
            "Requirement already satisfied: executing>=1.2.0 in /content/py38/lib/python3.8/site-packages (from stack-data->IPython) (2.2.1)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in /content/py38/lib/python3.8/site-packages (from stack-data->IPython) (3.0.1)\n",
            "Requirement already satisfied: pure-eval in /content/py38/lib/python3.8/site-packages (from stack-data->IPython) (0.2.3)\n"
          ]
        }
      ],
      "source": [
        "!source \"/content/py38/bin/activate\" && pip install matplotlib_inline IPython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dX_iw9JP10ZF",
        "outputId": "fe0a978e-2543-46f7-aa07-a510ce90c770"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Process is terminated.\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "VENV_PATH=\"/content/py38\"\n",
        "REPO_PATH=\"/content/drive/MyDrive/mmdet_nwdrka/mmdet-nwdrka\"\n",
        "SCRIPT_PATH=\"infer_batch.py\"\n",
        "\n",
        "source \"${VENV_PATH}/bin/activate\"\n",
        "\n",
        "python -V\n",
        "which python\n",
        "\n",
        "cd \"${REPO_PATH}\"\n",
        "python \"${SCRIPT_PATH}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3g2cbAwz1BkU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
